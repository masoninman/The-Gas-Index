{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tests = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters specific to this notebook\n",
    "ldc_fract_area_threshold = 0.001\n",
    "run_intersection_tract_ldc = True # when False, loads results saved from previous run\n",
    "test_urban_populations = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files from GIM & other GEM compilation:\n",
    "prod_leak_timestamp = '2020-11-12_0933'\n",
    "trans_leak_timestamp = '2020-11-30_1608'\n",
    "ldc_leak_rcei_timestamp = '2020-11-30_1610'\n",
    "\n",
    "gim_cities_file = 'GIM cities in index 2020-10-31.xlsx'\n",
    "parameters_file = 'GIM parameters file.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "lca_path = '/Users/masoninman/Dropbox/GEM/LCA of natural gas use/'\n",
    "inputs_path = lca_path + 'US cities LCA of gas model/US gas model inputs/'\n",
    "census_path = lca_path + 'US Census/'\n",
    "eia_176_path = lca_path + 'EIA data for LCA of gas/EIA-176 data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read parameters\n",
    "df = pd.read_excel(inputs_path + 'GIM parameters file.xlsx', sheet_name='main parameters')\n",
    "parameters_main = df.set_index('parameter name')['parameter value']\n",
    "\n",
    "data_year = int(parameters_main.at['data_year'])\n",
    "contiguous_us_only = parameters_main.at['contiguous_us_only']\n",
    "ch4_fract_in_ng_consumer_grade = parameters_main.at['ch4_fract_in_ng_consumer_grade']\n",
    "ch4_kg_per_mcf = parameters_main.at['ch4_kg_per_mcf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files from external sources:\n",
    "fips_file = 'US Census - center of population by state (2010 census) and FIPS Code.xlsx'\n",
    "operations_year_file = f'EIA-176 Type of Operations and Sector Items {data_year}.xlsx'\n",
    "ldc_population_served_file = 'LDC pop served and res-comm Mcf per person 2020-11-01_0946.xlsx'\n",
    "state_abbrev_file = 'US states and abbreviations.xlsx'\n",
    "urban_file = 'cb_2018_us_ua10_500k.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard conversions\n",
    "km2_per_m2 = 1e-6\n",
    "g_per_gg = 1e9\n",
    "ton_per_g = 1e-6\n",
    "gg_per_g = 1e-9\n",
    "gg_per_kg = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert volume NG to mass of CH4 it contains\n",
    "conversion_consumer_ng_mcf_to_ch4_gg = ch4_fract_in_ng_consumer_grade * ch4_kg_per_mcf * gg_per_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get state information (names, abbreviations, FIPS codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_state_abbreviations(state_abbrev_file):\n",
    "    states_df = pd.read_excel(inputs_path + state_abbrev_file)\n",
    "\n",
    "    states_abbrev_to_full_dict = states_df.set_index('abbrev')['state'].to_dict()\n",
    "    states_full_to_abbrev_dict = states_df.set_index('state')['abbrev'].to_dict()\n",
    "    \n",
    "    return(states_abbrev_to_full_dict, states_full_to_abbrev_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fips_file():\n",
    "    # get state codes (FIPS)\n",
    "    # https://www.census.gov/geographies/reference-files/2018/demo/popest/2018-fips.html\n",
    "    fips = pd.read_excel(inputs_path + fips_file, dtype={'STATEFP': str})\n",
    "\n",
    "    if contiguous_us_only==True:\n",
    "        fips = fips.loc[~fips['STNAME'].isin(['Alaska', 'Hawaii', 'Puerto Rico'])]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(states_abbrev_to_full_dict, states_full_to_abbrev_dict) = read_state_abbreviations(state_abbrev_file)\n",
    "fips = read_fips_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import state boundaries\n",
    "state_bound_folder = 'cb_2018_us_state_500k'\n",
    "state_bound = gpd.read_file(census_path + state_bound_folder)\n",
    "state_bound = state_bound.to_crs(epsg=2163)\n",
    "print(state_bound.crs)\n",
    "\n",
    "state_bound = state_bound.rename(columns={'STUSPS': 'state abbrev'})\n",
    "state_bound = state_bound.set_index('state abbrev')\n",
    "state_bound = state_bound[['geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_crs_mismatch(gdf_1, gdf_2):\n",
    "    if gdf_1.crs['init']==gdf_2.crs['init']:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR!\" + f\" CRS mismatch: gdf_1.crs: {gdf_1.crs}; gdf_2.crs: {gdf_2.crs}\")\n",
    "        \n",
    "    # no return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDCs data set from ORNL (via HIFLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes on ORNL:**\n",
    "* Data from Department of Homeland Security (DHS), [HIFLD](https://hifld-geoplatform.opendata.arcgis.com/datasets/natural-gas-local-distribution-company-service-territories)\n",
    "* [Metadata page](https://www.arcgis.com/sharing/rest/content/items/a3d48c142f88433ab77aa755a56aa07a/info/metadata/metadata.xml?format=default&output=html) says: \n",
    "  * Temporal extent: Beginning date: 2014-01-01, Ending date: 2017-12-31\n",
    "  * Reference System Information: Reference system identifier: 4326, Code space: EPSG\n",
    "    * However, when loading in GeoPandas, it says the CRS is 'epsg:3857'\n",
    "  * Version: 6.14(3.0.1)\n",
    "* typo in LDC name 'CONNETICUT NATURAL GAS CORP' (missing C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes on coordinate systems:**\n",
    "* EPSG:4326: WGS 84 -- WGS84 - World Geodetic System 1984, used in GPS\n",
    "  * https://epsg.io/4326\n",
    "  * Projected bounds: -180.0 -90.0 / 180.0 90.0 \n",
    "* EPSG:3857: WGS 84 / Pseudo-Mercator -- Spherical Mercator, Google Maps, OpenStreetMap, Bing, ArcGIS, ESRI\n",
    "  * https://epsg.io/3857\n",
    "  * Projected bounds: -20026376.39 -20048966.10 / 20026376.39 20048966.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ornl_path = lca_path + 'ORNL Natural Gas Local Distribution Company Service Territories (from DHS HIFLD) shp/'\n",
    "ornl_file = 'NG_LDC_Service_Terr.shp'\n",
    "ornl_init = gpd.read_file(ornl_path + ornl_file)\n",
    "print(f\"initial ORNL CRS: {ornl_init.crs}\")\n",
    "\n",
    "# convert to equal-area projection\n",
    "# Stack Overflow recommended ESPG 3035: https://gis.stackexchange.com/a/359955\n",
    "# but that is centered on Europe: https://epsg.io/3035\n",
    "# Can instead try ESPG 2163 (https://epsg.io/2163); \"US National Atlas Equal Area\", with UoM: m\n",
    "ldcs_ornl = ornl_init.to_crs(epsg=2163)\n",
    "print(f\"final ORNL CRS: {ldcs_ornl.crs}\")\n",
    "\n",
    "ldcs_ornl = ldcs_ornl.rename(columns={\n",
    "    'NAME': 'LDC name', \n",
    "    'STATE': 'LDC HQ state?', \n",
    "    'AREASQKM': 'LDC area km2'\n",
    "})\n",
    "ldcs_ornl['EIA company ID'] = ldcs_ornl['COMPID'] + ldcs_ornl['LDC_STATE']\n",
    "\n",
    "# filter out those with 'COMPID' == 'NOT AVAILABLE'\n",
    "ldcs_ornl = ldcs_ornl.loc[ldcs_ornl['COMPID']!='NOT AVAILABLE']\n",
    "\n",
    "# ldcs_ornl['GPD area km2'] = ldcs_ornl.area / 1e6\n",
    "# ldcs_ornl['area ratio'] = ldcs_ornl['GPD area km2'].div(ldcs_ornl['LDC area km2'])\n",
    "\n",
    "ldcs_keep_cols = ['LDC name', 'EIA company ID', 'geometry']  # , 'LDC area km2', 'GPD area km2', 'area ratio'\n",
    "ldcs_ornl = ldcs_ornl[ldcs_keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_ornl_eia_ids(ldcs_ornl, ldc_name, wrong_id, correct_id):\n",
    "    df = ldcs_ornl\n",
    "    \n",
    "    # get index for row to change\n",
    "    change_df = df.loc[\n",
    "        (df['LDC name']==ldc_name) & \n",
    "        (df['EIA company ID']==wrong_id)]\n",
    "    \n",
    "    if len(change_df)==1:\n",
    "        change_idx = change_df.index[0]\n",
    "        df.at[change_idx, 'EIA company ID'] = correct_id\n",
    "        print(f\"changed {ldc_name}\")\n",
    "        \n",
    "    elif len(change_df)==0:\n",
    "        print(f\"combination of name/ID not found: {ldc_name}, {wrong_id}\")\n",
    "        \n",
    "    elif len(change_df) > 1:\n",
    "        print(f\"found more than one row:\")\n",
    "        print(change_df)\n",
    "        \n",
    "    else:\n",
    "        print(f\"Unexpected other case for {ldc_name}, {wrong_id}\")\n",
    "        \n",
    "    ldcs_ornl\n",
    "    \n",
    "    return ldcs_ornl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix New York state shapefile issues:\n",
    "\n",
    "# in ORNL:\n",
    "# Problem is that National Grid territory shown combines upstate, Brooklyn/Staten Island, and rest of Long Island\n",
    "# Those are three different EIA IDs: 17610204NY, 17601565NY, 17617823NY\n",
    "# However, in ORNL listed as simply: 17610204NY\n",
    "\n",
    "# simplest solution: change ORNL EIA company ID to 17610204NY_17601565NY_17617823NY\n",
    "# then in EIA data, combine those three National Grid entries into one\n",
    "# This is not ideal because it's combining upstate NY and NYC, where consumption may be different\n",
    "# But it's a straightforward way to generate an estimate, and which is similar to the situation in many other urban areas\n",
    "\n",
    "ldcs_ornl['EIA company ID'] = ldcs_ornl['EIA company ID'].replace(\n",
    "    '17610204NY', '17610204NY_17601565NY_17617823NY'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional notes:\n",
    "\n",
    "# Others that are OK in ORNL:\n",
    "\n",
    "# Manhattan, north of Manhattan, part of Queens:\n",
    "# comp_full: “Consolidated Edison”; EIA company ID: 17602810NY\n",
    "\n",
    "# north of Con Ed territory & overlapping with NYC urban area\n",
    "# comp_full: “Central Hudson Gas and Electric”; EIA company ID: 17602168NY\n",
    "# comp_full: “NYS Electric Gas”; EIA company ID: 17610199NY\n",
    "# comp_full: “Orange and Rockland Utilities”; EIA company ID: 17610536NY\n",
    "\n",
    "# ================\n",
    "# New York State gas territories shapefile:\n",
    "\n",
    "# ConEd seems to be wrong; it shows service for Staten Island\n",
    "# However, ConEd says its Staten Island service is \"electric only\"\n",
    "# https://www.coned.com/en/business-partners/service-territories\n",
    "\n",
    "# Brooklyn (and Staten Island?)\n",
    "# comp_full: “National Grid - NYC”; EIA company ID: 17601565NY\n",
    "\n",
    "# rest of Long Island:\n",
    "# comp_full: “National Grid - Long Island”; EIA company ID: 17617823NY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "\n",
    "# change EIA company IDs for those that had duplicates, so something was definitely wrong\n",
    "ldcs_ornl = fix_ornl_eia_ids(ldcs_ornl, 'CENTREVILLE, TOWN OF', '17600003MS', '17602193MS')\n",
    "ldcs_ornl = fix_ornl_eia_ids(ldcs_ornl, 'TISHOMINGO NATURAL GAS SYSTEM', '17600003MS', '17619898MS')\n",
    "ldcs_ornl = fix_ornl_eia_ids(ldcs_ornl, 'LOBELVILLE, CITY OF', '17600183TN', '17608530TN')\n",
    "ldcs_ornl = fix_ornl_eia_ids(ldcs_ornl, 'ST. LAWRENCE GAS', '17614659NY', '17611894NY')\n",
    "ldcs_ornl = fix_ornl_eia_ids(ldcs_ornl, 'HALLOCK, CITY OF', '17617865MN', '17605402MN')\n",
    "ldcs_ornl = fix_ornl_eia_ids(ldcs_ornl, 'MIDAMERICAN ENERGY', '17631004NE', '17650920NE')\n",
    "\n",
    "# Duplicated IDs that were correct:\n",
    "# BLACK HILLS ENERGY has correct EIA company ID\n",
    "# VALLEY ENERGY, INC. has correct EIA company ID\n",
    "# Loretto has correct EIA company ID\n",
    "# HIBBING PUBLIC UTILITY COMM. has correct EIA company ID\n",
    "\n",
    "# There is an issue in the data with EIA company ID 17614635SD; \n",
    "# These are for Humboldt & Watertown (SD); had issue where these were separate in PHMSA, but didn't have matches in EIA\n",
    "# Did ORNL data derive from PHMSA, and they created their own crosswalk to EIA???\n",
    "# Anyway, exclude EIA company ID 17614635SD\n",
    "ldcs_ornl = ldcs_ornl.loc[ldcs_ornl['EIA company ID']!='17614635SD']\n",
    "\n",
    "# There is only 1 LDC name that's repeated; also only 1 COMPID repeated\n",
    "# both are for the same LDC: 'BLUEFIELD GAS', COMPID: 17601305\n",
    "# res & comm deliveries are the same, but area and geometry aren't the same\n",
    "# may be that one is serving in WV and one serving in VA (based on 'LDC_STATE')\n",
    "# guessed that VA one might be ID 17673805VA (\"APPALACHIAN NATURAL GAS\"), \n",
    "# but ORNL set already has an LDC in VA of that name (COMPID 17673805)\n",
    "# to avoid problems, exclude 'BLUEFIELD GAS', COMPID: 17601305\n",
    "ldcs_ornl = ldcs_ornl.loc[(ldcs_ornl['EIA company ID']!='17601305WV') & (ldcs_ornl['LDC name']!='BLUEFIELD GAS')]\n",
    "ldcs_ornl = ldcs_ornl.loc[(ldcs_ornl['EIA company ID']!='17601305VA') & (ldcs_ornl['LDC name']!='BLUEFIELD GAS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs in ORNL not found in my EIA files:\n",
    "# explanations and changes as needed\n",
    "\n",
    "# Washington Gas:\n",
    "# DC portion has same ID as crosswalk\n",
    "# VA portion uses 17616173VA; that hasn't been used since 2004; change to 17671254VA\n",
    "ldcs_ornl = fix_ornl_eia_ids(ldcs_ornl, 'WASHINGTON GAS', '17616173VA', '17671254VA')\n",
    "# MD portion uses 17671254MD; I don't see that used anywhere (neither in my files nor online); change to 17616172MD\n",
    "ldcs_ornl = fix_ornl_eia_ids(ldcs_ornl, 'WASHINGTON GAS', '17671254MD', '17616172MD')\n",
    "\n",
    "# 17606391ID (INTERMOUNTAIN GAS COMPANY) not in ORNL? (What is serving Boise, ID, in ORNL?)\n",
    "# change INTERMOUNTAIN GAS CO 17606931ID to 17606391ID\n",
    "# seems there was a typo in manually entering; digits switched\n",
    "ldcs_ornl = fix_ornl_eia_ids(ldcs_ornl, 'INTERMOUNTAIN GAS CO', '17606931ID', '17606391ID')\n",
    "\n",
    "# 17672060LA (ATMOS ENERGY CORPORATION) not in ORNL? (What is serving New Orleans, LA, in ORNL?)\n",
    "# change ATMOS ENERGY - LOUSIANA DIVISION 1760016LA to 17672060LA\n",
    "# seems that the ID is improperly formatted; not enough digits; also typo\n",
    "ldcs_ornl = fix_ornl_eia_ids(ldcs_ornl, 'ATMOS ENERGY - LOUSIANA DIVISION', '1760016LA', '17672060LA')\n",
    "\n",
    "# 17699051NC (PIEDMONT NATURAL GAS) not in ORNL\n",
    "# (ORNL map doesn't show any LDC for the core of Charlotte, NC; only service for some outlying parts; is that correct???)\n",
    "# change PIEDMONT NATURAL GAS 1769905NC to 17699051NC\n",
    "# seems there was a typo in manually entering; digit missing\n",
    "ldcs_ornl = fix_ornl_eia_ids(ldcs_ornl, 'PIEDMONT NATURAL GAS', '1769905NC', '17699051NC')\n",
    "\n",
    "# 17675803NH (LIBERTY UTILITIES DBA ENERGY NORTH N) not in ORNL? What is serving Manchester, NH?\n",
    "# change LIBERTY UTILITIES (ENERGYNORTH) 17604829NH to 17675803NH\n",
    "# ID used seems to be old one, last used in 2011\n",
    "ldcs_ornl = fix_ornl_eia_ids(ldcs_ornl, 'LIBERTY UTILITIES (ENERGYNORTH)', '17604829NH', '17675803NH')\n",
    "\n",
    "# 17673850NM (NEW MEXICO GAS COMPANY) not in ORNL? What is serving Albuquerque, NM?\n",
    "# change NEW MEXICO GAS COMPANY 17617270NM to 17673850NM\n",
    "# ID used seems to be old one, last used in 2009\n",
    "ldcs_ornl = fix_ornl_eia_ids(ldcs_ornl, 'NEW MEXICO GAS COMPANY', '17617270NM', '17673850NM')\n",
    "\n",
    "# 17673240WV (MOUNTAINEER GAS CO) not in ORNL? What is serving Charleston, WV?\n",
    "# That ID hasn't been used since 2004\n",
    "# change MOUNTAINEER GAS CO. 17616239WV to 17673240WV\n",
    "ldcs_ornl = fix_ornl_eia_ids(ldcs_ornl, 'MOUNTAINEER GAS CO.', '17616239WV', '17673240WV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_area_from_territory(df, ldc_a_id, ldc_b_id):\n",
    "    \"\"\"\n",
    "    When one LDC (LDC A) reports covering a large area that encompasses territory of another LDC (LDC B),\n",
    "    but it turns out LDC A doesn't actually cover the territory of LDC B,\n",
    "    then this function subtracts, from LDC A, the territory of LDC B.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_no_change = df.loc[df['EIA company ID']!=ldc_a_id]\n",
    "    ldc_a = df.loc[df['EIA company ID']==ldc_a_id].reset_index(drop=True)\n",
    "    ldc_b = df.loc[df['EIA company ID']==ldc_b_id].reset_index(drop=True)\n",
    "    \n",
    "    # TEST\n",
    "    if ldc_a.crs['init'] != ldc_b.crs['init']:\n",
    "        print(\"ERROR!\" + f\" Mismatch of CRS: ldc_a.crs: {ldc_a.crs}; ldc_b.crs: {ldc_b.crs}\")\n",
    "    # END OF TEST\n",
    "    \n",
    "    ldc_a_diff_ldc_b = gpd.overlay(ldc_a, ldc_b, how='difference').reset_index(drop=True)\n",
    "    \n",
    "    # recombine\n",
    "    df_new = df_no_change.append(ldc_a_diff_ldc_b).reset_index(drop=True)\n",
    "    \n",
    "    # test len\n",
    "    if len(ldcs_ornl)==len(df_new):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Error!\" + f\" There is a mismatch in the lens: len(ldcs_ornl): {len(ldcs_ornl)} & len(df): {len(df)}\")\n",
    "    # end of test len\n",
    "        \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconfigure_washington_gas(ldcs_ornl, state_bound):\n",
    "    \"\"\"\n",
    "    Washington Gas MD includes parts in WV & VA\n",
    "    Washington Gas VA is only VA--but doesn't include all the operations in VA, because of the part included with MD\n",
    "    Washington Gas DC is OK, so don't need to bring it in\n",
    "    \"\"\"\n",
    "    \n",
    "    # dissolve Washington Gas territories stated to be in VA & MD; create one multipolygon\n",
    "    mask_wash_gas_to_change = ldcs_ornl['EIA company ID'].isin(['17671254VA', '17616172MD'])\n",
    "    wash_gas_to_change = ldcs_ornl.loc[mask_wash_gas_to_change]\n",
    "    wash_gas_to_change = wash_gas_to_change.dissolve(by='LDC name')[['geometry']].reset_index()\n",
    "    \n",
    "    # change state_bound CRS if need be\n",
    "    if ldcs_ornl.crs['init']=='epsg:2163':\n",
    "        state_bound = state_bound.to_crs(epsg=2163)\n",
    "    else:\n",
    "        print(f\"ldcs_ornl.crs: {ldcs_ornl.crs}; state_bound.crs: {state_bound.crs}\")\n",
    "    \n",
    "    new_entries_list = [] # initialize\n",
    "    \n",
    "    # TEST\n",
    "    if state_bound.crs['init'] != wash_gas_to_change.crs['init']:\n",
    "        print(\"ERROR!\" + f\" Mismatch of CRS: state_bound_sel.crs: {state_bound_sel.crs}; wash_gas_to_change.crs: {wash_gas_to_change.crs}\")\n",
    "    # END OF TEST\n",
    "    \n",
    "    # change geometry for the selected EIA IDs\n",
    "    # from the dissolved geometry, select only the part within the state listed in the EIA ID\n",
    "    for eia_id in ['17671254VA', '17616172MD']:\n",
    "        state_abbrev = eia_id[-2:]\n",
    "        state_bound_sel = state_bound.loc[state_bound.index==state_abbrev]\n",
    "        wash_gas_new = gpd.overlay(state_bound_sel, wash_gas_to_change, how='intersection')\n",
    "        wash_gas_new['EIA company ID'] = eia_id\n",
    "        \n",
    "        new_entries_list += [wash_gas_new]\n",
    "\n",
    "    # concat new entries, then append to main gdf\n",
    "    new_entries_gdf = pd.concat(new_entries_list, sort=False)\n",
    "    not_changed = ldcs_ornl.loc[~mask_wash_gas_to_change]\n",
    "    \n",
    "    ldcs_ornl = not_changed.append(new_entries_gdf, sort=False).reset_index(drop=True)\n",
    "    \n",
    "    return ldcs_ornl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconfigure_northeast_ohio_gas(ldcs_ornl, state_bound):\n",
    "    \"\"\"\n",
    "    Northeast Ohio Natural Gas Corp (17695242OH) took over:\n",
    "    Orwell Natural Gas Co. (17695266OH)\n",
    "    Brainard Gas Corp. (17695236OH)\n",
    "    https://www.neogas.com/PDF/FINAL MERGER BILL INSERT.pdf\n",
    "    \n",
    "    Combine their service territories into one.\n",
    "    \"\"\"\n",
    "    \n",
    "    # dissolve Washington Gas territories stated to be in VA & MD; create one multipolygon\n",
    "    mask_to_change = ldcs_ornl['EIA company ID'].isin(['17695242OH', '17695266OH', '17695236OH'])\n",
    "    not_changed = ldcs_ornl.copy().loc[~mask_to_change]\n",
    "    \n",
    "    to_change = ldcs_ornl.copy().loc[mask_to_change]\n",
    "    to_change['LDC name'] = 'NORTHEAST OHIO NATURAL GAS + ORWELL + BRAINARD'\n",
    "    to_change['EIA company ID'] = '17695242OH_17695266OH_17695236OH'\n",
    "    to_change = to_change.dissolve(by=['LDC name', 'EIA company ID'])[['geometry']].reset_index()\n",
    "    \n",
    "    \n",
    "    # change state_bound CRS if need be\n",
    "    if ldcs_ornl.crs['init']=='epsg:2163':\n",
    "        state_bound = state_bound.to_crs(epsg=2163)\n",
    "    else:\n",
    "        print(f\"ldcs_ornl.crs: {ldcs_ornl.crs}; state_bound.crs: {state_bound.crs}\")\n",
    "    \n",
    "    # TEST\n",
    "    if state_bound.crs['init'] != to_change.crs['init']:\n",
    "        print(\"ERROR!\" + f\" Mismatch of CRS: state_bound_sel.crs: {state_bound_sel.crs}; to_change.crs: {to_change.crs}\")\n",
    "    # END OF TEST\n",
    "    \n",
    "    ldcs_ornl = not_changed.append(to_change, sort=False).reset_index(drop=True)\n",
    "    \n",
    "    return ldcs_ornl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldcs_ornl = reconfigure_washington_gas(ldcs_ornl, state_bound)\n",
    "ldcs_ornl = reconfigure_northeast_ohio_gas(ldcs_ornl, state_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Omaha, NE: \n",
    "# from Black Hills Energy (17631004NE), subtract territory of Metropolitian Utilities of Omaha (17609407NE)\n",
    "ldcs_ornl = subtract_area_from_territory(ldcs_ornl, '17631004NE', '17609407NE')\n",
    "\n",
    "# For Chicago, IL:\n",
    "# from NICOR GAS COMPANY (17610322IL), subtract territory of PEOPLES GAS LT & COKE CO (17610960IL)\n",
    "ldcs_ornl = subtract_area_from_territory(ldcs_ornl, '17610322IL', '17610960IL')\n",
    "\n",
    "# For Mesa, AZ:\n",
    "# from SOUTHWEST GAS CORPORATION (17616576AZ), subtract territory of MESA CITY OF (17609381AZ)\n",
    "# based on: https://www.selectmesa.com/business-environment/utilities\n",
    "ldcs_ornl = subtract_area_from_territory(ldcs_ornl, '17616576AZ', '17609381AZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove territory from Atlanta Gas Light (17600626GA) where it overlaps with Austell (17600689GA)\n",
    "ldcs_ornl = subtract_area_from_territory(ldcs_ornl, '17600626GA', '17600689GA')\n",
    "\n",
    "# note, for Lawrenceville (17608261GA), couldn't see evidence that it has exclusive service in the area\n",
    "# so not subtracting Lawrenceville territory from Atlanta Gas Light territory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes: there are some mismatches in names between ORNL and recent EIA data, but they are actually OK\n",
    "\n",
    "# for EIA company ID 17611093PA:\n",
    "# EIA has PEOPLES GAS COMPANY, but ORNL has \"PHILLIPS T W GAS & OIL CO\"\n",
    "# This is OK; Peoples Gas website says (https://www.peoples-gas.com/about/): \n",
    "# \"Peoples has been providing natural gas service in western Pennsylvania for more than 130 years. \n",
    "# In the last five years, Peoples purchased the T.W. Phillips Gas & Oil Company and Equitable Gas.\"\n",
    "\n",
    "# for EIA company ID 17616572MO:\n",
    "# EIA has \"SPIRE MISSOURI INC\", but ORNL has \"LACLEDE GAS CO\"\n",
    "# Spire took over Laclede: https://www.spireenergy.com/welcome-laclede-gas-customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: ORNL includes KINDER MORGAN INC (17617235NE) covering NE\n",
    "# EIA Company List says that is actually BLACK HILLS GAS DISTRIBUTION LLC\n",
    "# However, that has gone inactive; was last active 2016\n",
    "# so exclude 17617235NE from ORNL\n",
    "# (also fixes problem with Lincoln, NE & Omaha, NE)\n",
    "ldcs_ornl = ldcs_ornl.loc[ldcs_ornl['EIA company ID']!='17617235NE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuscarora (17695180CA) is a transmission company;\n",
    "# Still active in CA in 2018, but had no res-comm sales, and very little sales to any end-consumers\n",
    "# exclude from ORNL\n",
    "ldcs_ornl = ldcs_ornl.loc[ldcs_ornl['EIA company ID']!='17695180CA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: check if there are any duplicated EIA company IDs\n",
    "dups = ldcs_ornl.loc[ldcs_ornl['EIA company ID'].duplicated(keep=False)].sort_values(by='EIA company ID')\n",
    "if len(dups)==0:\n",
    "    pass\n",
    "else:\n",
    "    print(dups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EIA data on volumes\n",
    "Merge in EIA data on gas volumes for specified analysis year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_national_grid_in_new_york(df):\n",
    "    \"\"\"\n",
    "    Problem with ORNL data for National Grid in New York: \n",
    "    It listed a single EIA company ID, but that was actually only National Grid operations in upstate NY.\n",
    "    So in ORNL, changed EIA company ID to be composite of all National Grid operations in NY state.\n",
    "    \n",
    "    Here, consolidate all National Grid operations in NY state, \n",
    "    so that gas volumes from EIA correspond to territory in ORNL.\n",
    "    \"\"\"\n",
    "    # combine National Grid listings for New York State into one row\n",
    "    nat_grid_ids = ['17610204NY', '17601565NY', '17617823NY']\n",
    "    nat_grid_nys = df.copy().loc[df['EIA company ID'].isin(nat_grid_ids)]\n",
    "    nat_grid_nys['EIA company ID'] = '17610204NY_17601565NY_17617823NY'\n",
    "    nat_grid_nys['Company Name'] = 'NATIONAL GRID (ALL NYS)'\n",
    "    nat_grid_nys = nat_grid_nys.groupby(['Year', 'State', 'EIA company ID', 'Company Name']).sum().reset_index()\n",
    "    \n",
    "    # exclude the individual rows from df\n",
    "    df = df.loc[~df['EIA company ID'].isin(nat_grid_ids)]\n",
    "    \n",
    "    # append the consolidated row\n",
    "    df = df.append(nat_grid_nys, sort=False).reset_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_northeast_ohio_gas(df):\n",
    "    \"\"\"\n",
    "    Problem with LDCs in Ohio: \n",
    "    Northeast Ohio Natural Gas Corp (17695242OH) took over:\n",
    "    Orwell Natural Gas Co. (17695266OH)\n",
    "    Brainard Gas Corp. (17695236OH)\n",
    "    https://www.neogas.com/PDF/FINAL MERGER BILL INSERT.pdf\n",
    "    \n",
    "    Combine them all into one.\n",
    "    \"\"\"\n",
    "    # combine National Grid listings for New York State into one row\n",
    "    ne_oh_ids = ['17695242OH', '17695266OH', '17695236OH']\n",
    "    ne_oh = df.copy().loc[df['EIA company ID'].isin(ne_oh_ids)]\n",
    "    ne_oh['EIA company ID'] = '17695242OH_17695266OH_17695236OH'\n",
    "    ne_oh['Company Name'] = 'NORTHEAST OHIO NATURAL GAS + ORWELL + BRAINARD'\n",
    "    ne_oh = ne_oh.groupby(['Year', 'State', 'EIA company ID', 'Company Name']).sum().reset_index()\n",
    "    \n",
    "    # exclude the individual rows from df\n",
    "    df = df.loc[~df['EIA company ID'].isin(ne_oh)]\n",
    "    \n",
    "    # append the consolidated row\n",
    "    df = df.append(ne_oh, sort=False).reset_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_census_tract_population_data():\n",
    "    acs_2018_path = lca_path + 'US Census/population by census tract - ACS 5-Year (2018)/'\n",
    "    part1_path = 'AL-FL ACSDT5Y2018.B01003_2020-10-30T180506/'\n",
    "    part1_file = 'ACSDT5Y2018.B01003_data_with_overlays_2020-10-30T180457.csv'\n",
    "\n",
    "    part2_path = 'GA-ME ACSDT5Y2018.B01003_2020-10-30T180822/'\n",
    "    part2_file = 'ACSDT5Y2018.B01003_data_with_overlays_2020-10-30T180807.csv'\n",
    "\n",
    "    part3_path = 'MD-NH ACSDT5Y2018.B01003_2020-10-30T181100/'\n",
    "    part3_file = 'ACSDT5Y2018.B01003_data_with_overlays_2020-10-30T181052.csv'\n",
    "\n",
    "    part4_path = 'NJ-RI ACSDT5Y2018.B01003_2020-10-30T181340/'\n",
    "    part4_file = 'ACSDT5Y2018.B01003_data_with_overlays_2020-10-30T181331.csv'\n",
    "\n",
    "    part5_path = 'SC-WY ACSDT5Y2018.B01003_2020-10-30T181603/'\n",
    "    part5_file = 'ACSDT5Y2018.B01003_data_with_overlays_2020-10-30T181553.csv'\n",
    "    \n",
    "    part1 = pd.read_csv(acs_2018_path + part1_path + part1_file, header=1)\n",
    "    part2 = pd.read_csv(acs_2018_path + part2_path + part2_file, header=1)\n",
    "    part3 = pd.read_csv(acs_2018_path + part3_path + part3_file, header=1)\n",
    "    part4 = pd.read_csv(acs_2018_path + part4_path + part4_file, header=1)\n",
    "    part5 = pd.read_csv(acs_2018_path + part5_path + part5_file, header=1)\n",
    "    \n",
    "    # concat all into one df\n",
    "    df = pd.concat([part1, part2, part3, part4, part5], sort=False)\n",
    "    df = df.drop('Margin of Error!!Total', axis=1)\n",
    "    df = df.rename(columns={\n",
    "        'id': 'tract full ID',\n",
    "        'Estimate!!Total': 'tract pop',\n",
    "    })\n",
    "    \n",
    "    # split out GEOIDs & states\n",
    "    df['tract GEOID'] = df['tract full ID'].str.split('1400000US').str[-1].astype(str)\n",
    "    df['state'] = df['Geographic Area Name'].str.split(', ').str[-1]\n",
    "    df = df.drop('tract full ID', axis=1)\n",
    "    \n",
    "    tract_pop = df\n",
    "    \n",
    "    return tract_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_pop = compile_census_tract_population_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census tract boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tract_st(FIPS_code):\n",
    "    # read census tract shapefile (one file for each state) \n",
    "    tract_st_path = lca_path + f'TIGER-Line Census Tract 2018/tl_2018_{FIPS_code}_tract/'\n",
    "    tract_st_file = f'tl_2018_{FIPS_code}_tract.shp'\n",
    "    tract_st = gpd.read_file(tract_st_path + tract_st_file)\n",
    "\n",
    "    tract_keep_cols = ['GEOID', 'geometry'] # 'TRACTCE', 'MTFCC', 'NAME', 'NAMELSAD'\n",
    "    tract_st = tract_st[tract_keep_cols]\n",
    "    tract_st = tract_st.rename(columns={'GEOID': 'tract GEOID'})\n",
    "\n",
    "    tract_st_cart = tract_st.to_crs(epsg=2163)\n",
    "    \n",
    "    return tract_st_cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_tract_data(fips, contiguous_us_only):\n",
    "    # iterate through all states (based on FIPS codes) to read files and put into one df\n",
    "    all_tracts_list = [] # initialize\n",
    "    for fips_code in fips['STATEFP']:\n",
    "        print(f\"processing FIPS code {fips_code}\")\n",
    "        tract_st_cart = read_tract_st(fips_code)\n",
    "        all_tracts_list += [tract_st_cart]\n",
    "\n",
    "    all_tracts = pd.concat(all_tracts_list, sort=False)\n",
    "    \n",
    "    # convert to equal area projection, before calculating area\n",
    "    all_tracts = all_tracts.to_crs(epsg=2163)\n",
    "    print(f\"all_tracts.crs: {all_tracts.crs}\")\n",
    "\n",
    "    # calculate total area of each tract\n",
    "    all_tracts['tract km2'] = all_tracts.area * km2_per_m2\n",
    "\n",
    "    # merge population data; attribution merge (not spatial merge)\n",
    "    # https://geopandas.org/mergingdata.html\n",
    "    all_tracts = all_tracts.merge(tract_pop, on='tract GEOID')\n",
    "\n",
    "    all_tracts['state abbrev'] = all_tracts['state'].replace(states_full_to_abbrev_dict)\n",
    "    \n",
    "    all_tracts['pop per km2'] = all_tracts['tract pop'] / all_tracts['tract km2']\n",
    "    \n",
    "    all_tracts = all_tracts.drop([\n",
    "        'Geographic Area Name',\n",
    "        # 'NAMELSAD'\n",
    "    ], axis=1)\n",
    "    \n",
    "    return all_tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the tracts from state files\n",
    "all_tracts = compile_tract_data(fips, contiguous_us_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for graphics\n",
    "# tract_ga_pop = all_tracts.copy().loc[all_tracts['state']=='Georgia']\n",
    "# tract_ga_pop['pop per km2'] = tract_ga_pop['tract pop'].div(tract_ga_pop['tract km2'])\n",
    "\n",
    "# # export\n",
    "# tract_ga_pop.to_file('tract_ga_pop', driver ='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for graphics\n",
    "# tract_oh_pop = all_tracts.copy().loc[all_tracts['state']=='Ohio']\n",
    "# tract_oh_pop['pop per km2'] = tract_oh_pop['tract pop'].div(tract_oh_pop['tract km2'])\n",
    "\n",
    "# # export\n",
    "# tract_oh_pop.to_file('tract_oh_pop', driver ='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Urban areas\n",
    "* US Census, Cartographic Boundary Files, Urban Areas\n",
    "* https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_urban_areas(urban_file):\n",
    "    \"\"\"\n",
    "    Read file from US Census for boundaries of urban areas.\n",
    "    \n",
    "    Convert to equal area projection to match CRS of other data sets.\n",
    "    \"\"\"\n",
    "    urban_path = lca_path + 'US Census/cb_2018_us_ua10_500k/'\n",
    "    urban = gpd.read_file(urban_path + urban_file)\n",
    "    urban = urban.to_crs(epsg=2163)\n",
    "    \n",
    "    print(f\"After conversion, urban.crs: {urban.crs}\")\n",
    "\n",
    "    urban = urban.rename(columns={\n",
    "        'NAME10': 'urban name',\n",
    "        'ALAND10': 'urban area (units?)',\n",
    "        'GEOID10': 'urban GEOID',\n",
    "    })\n",
    "\n",
    "    urban_keep_cols = ['urban name', 'geometry'] # 'urban GEOID'\n",
    "    urban = urban[urban_keep_cols]\n",
    "\n",
    "    return urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban = read_urban_areas(urban_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: check that population counts make sense\n",
    "* Do intersection of census tracts and urban area boundaries\n",
    "* Calculate population within each urban area\n",
    "* Compare against Census data on urban area populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_intersection_urban_tract(urban, all_tracts):\n",
    "    \"\"\"\n",
    "    Iterate over each state, getting its tract data, \n",
    "    then doing intersection with all urban areas in the state.\n",
    "    \"\"\"\n",
    "    results_list = [] # initialize\n",
    "       \n",
    "    for fips_row in fips.index:\n",
    "        # get one state's tract data\n",
    "        state_full = fips.at[fips_row, 'STNAME']\n",
    "        st_tract = all_tracts.loc[all_tracts['state']==state_full]\n",
    "    \n",
    "        # get state abbrev corresponding to state_full\n",
    "        state_abbrev = states_full_to_abbrev_dict[state_full]\n",
    "        \n",
    "        print(f\"processing state: {state_full}\") # for UI\n",
    "    \n",
    "        urban_sel = urban.loc[urban['urban name'].str.contains(state_abbrev)]\n",
    "    \n",
    "        # TEST\n",
    "        if st_tract.crs['init'] != urban_sel.crs['init']:\n",
    "            print(\"ERROR!\" + f\" Mismatch of CRS: st_tract.crs: {st_tract.crs}; urban_sel.crs: {urban_sel.crs}\")\n",
    "        # END OF TEST\n",
    "    \n",
    "        # do intersection\n",
    "        gdf = gpd.overlay(\n",
    "            st_tract,\n",
    "            urban_sel,  \n",
    "            how='intersection')\n",
    "\n",
    "        gdf['tract int km2'] = gdf['geometry'].area * km2_per_m2\n",
    "        gdf['tract area fract'] = gdf['tract int km2'].div(gdf['tract km2'])\n",
    "\n",
    "        tract_pop_int_total = gdf[['tract GEOID', 'tract pop']].drop_duplicates()['tract pop'].sum()\n",
    "\n",
    "        # calculate sums of fractional areas; used to reweight\n",
    "        tract_fract_sums = gdf.groupby('tract GEOID')['tract area fract'].sum()\n",
    "        tract_fract_sums = tract_fract_sums.reset_index()\n",
    "        tract_fract_sums = tract_fract_sums.rename(columns={'tract area fract': 'tract area fract sum'})\n",
    "\n",
    "        # merge these sums into main gdf\n",
    "        gdf = gdf.merge(tract_fract_sums, on=['tract GEOID'])\n",
    "        gdf['tract area fract reweight'] = gdf['tract area fract'].div(gdf['tract area fract sum'])\n",
    "        gdf['pop tract'] = gdf['tract pop'] * gdf['tract area fract reweight']\n",
    "\n",
    "        # TEST: check that population sum is correct\n",
    "        tract_pop_int_sums = gdf.groupby(['tract GEOID', 'tract pop'])[['pop tract']].sum() # removed from groupby: 'NAMELSAD'\n",
    "        tract_pop_int_total_after_reweight = tract_pop_int_sums['pop tract'].sum()\n",
    "        pop_diff = tract_pop_int_total - tract_pop_int_total_after_reweight\n",
    "        if abs(pop_diff) < 1e-3:\n",
    "            pass\n",
    "        else:\n",
    "            print('Error!' + f\" There was a difference in the population after reweighting\")\n",
    "            print(f\"initial:    {tract_pop_int_total}\")\n",
    "            print(f\"reweighted: {tract_pop_int_total_after_reweight}\")\n",
    "        # END OF TEST\n",
    "        \n",
    "        # put FIPS code into gdf\n",
    "        gdf['FIPS'] = fips_row\n",
    "\n",
    "        # for each urban area, calculate population\n",
    "        # (taking into account overlaps handled above)\n",
    "        df = gdf.groupby(['urban name', 'FIPS'])[['pop tract']].sum()\n",
    "        df = df.reset_index()\n",
    "        df = df.rename(columns={'pop tract': 'pop urban'})\n",
    "        df = df.sort_values(by=['pop urban'], ascending=False)\n",
    "        \n",
    "        results_list += [df]\n",
    "        \n",
    "    urban_population = pd.concat(results_list, sort=False)\n",
    "        \n",
    "    return urban_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_tests == True:\n",
    "    urban_population = test_intersection_urban_tract(urban, all_tracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get cities in index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gim_cities = pd.read_excel(inputs_path + gim_cities_file, dtype={'UACE': str, 'GEOID': str})\n",
    "sel_urban_areas = gim_cities['Census urban area name'].tolist()\n",
    "\n",
    "# print(f\"Show list before excluding any: {sel_urban_areas}\")\n",
    "\n",
    "# exclude urban areas that will be handled separately\n",
    "sel_urban_areas.remove('Cedar Rapids, IA')\n",
    "sel_urban_areas.remove('Lawrence, KS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### notes on urban areas excluded, to handle separately:\n",
    "* **Cedar Rapids, IA:** served by MidAmerican Energy, according to company's map; but not shown in ORNL serving the city\n",
    "* **Lawrence, KS:** ORNL map shows it being served by both Black Hills Energy and Atmos; however, according to Kansas PUC and the city, service is only from Black Hills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate population served by each LDC (across whole territory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_tract_ldc(ldcs_ornl, all_tracts):\n",
    "    \"\"\"\n",
    "    Iterate over each state, getting its tract data, \n",
    "    then doing intersection with all LDCs operating in the state.\n",
    "    \"\"\"\n",
    "    results_list = [] # initialize\n",
    "    \n",
    "    for fips_row in fips.index:\n",
    "        # get one state's tract data\n",
    "        state_full = fips.at[fips_row, 'STNAME']\n",
    "        st_tract = all_tracts.loc[all_tracts['state']==state_full]\n",
    "\n",
    "        print(f\"processing {state_full}\") # for UI\n",
    "        \n",
    "        # get state abbrev corresponding to state_full\n",
    "        state_abbrev = states_full_to_abbrev_dict[state_full]\n",
    "        ldcs_st = ldcs_ornl.loc[ldcs_ornl['EIA company ID'].str[-2:]==state_abbrev]\n",
    "    \n",
    "        # TEST\n",
    "        if st_tract.crs['init'] != ldcs_st.crs['init']:\n",
    "            print(\"ERROR!\" + f\" Mismatch of CRS: st_tract.crs: {st_tract.crs}; ldcs_st.crs: {ldcs_st.crs}\")\n",
    "        # END OF TEST\n",
    "    \n",
    "        # do intersection\n",
    "        gdf = gpd.overlay(\n",
    "            st_tract,\n",
    "            ldcs_st,  \n",
    "            how='intersection')\n",
    "\n",
    "        gdf['tract int km2'] = gdf['geometry'].area * km2_per_m2\n",
    "        gdf['tract area fract'] = gdf['tract int km2'].div(gdf['tract km2'])\n",
    "\n",
    "        tract_pop_int_total = gdf[['tract GEOID', 'tract pop']].drop_duplicates()['tract pop'].sum()\n",
    "\n",
    "        # calculate sums of fractional areas; used to reweight\n",
    "        tract_fract_sums = gdf.groupby('tract GEOID')['tract area fract'].sum()\n",
    "        tract_fract_sums = tract_fract_sums.reset_index()\n",
    "        tract_fract_sums = tract_fract_sums.rename(columns={'tract area fract': 'tract area fract sum'})\n",
    "\n",
    "        # merge these sums into main gdf\n",
    "        gdf = gdf.merge(tract_fract_sums, on=['tract GEOID'])\n",
    "        gdf['tract area fract reweight'] = gdf['tract area fract'].div(gdf['tract area fract sum'])\n",
    "        gdf['LDC pop tract'] = gdf['tract pop'] * gdf['tract area fract reweight']\n",
    "\n",
    "        # TEST: check that population sum is correct\n",
    "        tract_pop_int_sums = gdf.groupby(['tract GEOID', 'tract pop'])[['LDC pop tract']].sum()\n",
    "        tract_pop_int_total_after_reweight = tract_pop_int_sums['LDC pop tract'].sum()\n",
    "        pop_diff = tract_pop_int_total - tract_pop_int_total_after_reweight\n",
    "        if abs(pop_diff) < 1e-3:\n",
    "            pass\n",
    "        else:\n",
    "            print('Error!' + f\" There was a difference in the population after reweighting\")\n",
    "            print(f\"initial:    {tract_pop_int_total}\")\n",
    "            print(f\"reweighted: {tract_pop_int_total_after_reweight}\")\n",
    "        # END OF TEST\n",
    "\n",
    "        # for each LDC, calculate population served\n",
    "        df = gdf.groupby(['LDC name', 'EIA company ID'])[['LDC pop tract']].sum()\n",
    "        \n",
    "        df = df.reset_index()\n",
    "        df = df.rename(columns={'LDC pop tract': 'LDC pop served'})\n",
    "        df = df.sort_values(by=['LDC pop served'], ascending=False)\n",
    "\n",
    "        results_list += [df]\n",
    "        \n",
    "    ldc_population_served = pd.concat(results_list, sort=False)\n",
    "        \n",
    "    return ldc_population_served"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldc_population_served = intersection_tract_ldc(ldcs_ornl, all_tracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In each urban area, for each LDC, calculate population served & gas delivered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_tract_pop_to_one_ldc(tract_sel, ldcs_sel_urb_tract, ldcs_sel_urb):\n",
    "    tract_results = pd.DataFrame() # initialize\n",
    "    \n",
    "    # TEST:\n",
    "    if len(ldcs_sel_urb_tract) > 1:\n",
    "        print(\"ERROR!\" + f\" For this function, supposed to be only 1 LDC; len(ldcs_sel_urb_tract): {len(ldcs_sel_urb_tract)}\")\n",
    "    \n",
    "    ldcs_sel_urb_tract['pop served'] = ldcs_sel_urb_tract['pop per km2'] * ldcs_sel_urb_tract['km2 served']\n",
    "\n",
    "    tract_results = tract_results.append(ldcs_sel_urb_tract, sort=False)\n",
    "    \n",
    "    # to get portion of tract that is not in LDC's territory:\n",
    "    no_ldc = gpd.overlay(tract_sel, ldcs_sel_urb, how='difference').reset_index(drop=True)\n",
    "    no_ldc['km2 served'] = no_ldc.area * km2_per_m2\n",
    "    no_ldc['pop served'] = no_ldc['pop per km2'] * no_ldc['km2 served']\n",
    "    no_ldc['urban name'] = sel_urb_name\n",
    "    no_ldc['EIA company ID'] = 'no LDC and/or not in urban'\n",
    "    no_ldc['LDC name'] = 'no LDC and/or not in urban'\n",
    "    tract_results = tract_results.append(no_ldc, sort=False)\n",
    "    \n",
    "    # TEST: check that the LDC area & non-LDC area is summing to total area\n",
    "    tract_results_area_ldc_and_non = tract_results['km2 served'].sum()\n",
    "    tract_area_tot = (tract_sel.area * km2_per_m2).max()\n",
    "    diff = tract_area_tot - tract_results_area_ldc_and_non\n",
    "    fract_diff = diff / tract_area_tot\n",
    "    if abs(fract_diff) > 0.01:\n",
    "        print(\"------ ERROR!\" + f\" The sum of areas for LDCs and no LDC service was not the same as the tract total area!\")\n",
    "        print(f\"Tract total area: {tract_area_tot}; fract_diff: {fract_diff}\")\n",
    "\n",
    "    return tract_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_tract_pop_between_two_ldcs(tract_sel, sel_urban_area, ldcs_ids):\n",
    "    tract_results = pd.DataFrame() # initialize\n",
    "    \n",
    "    ldc1_id = ldcs_ids[0]\n",
    "    ldc2_id = ldcs_ids[1]\n",
    "\n",
    "    # split pop between the 2 LDCs, using all 4 combinations:\n",
    "    # only LDC1, only LDC2, both LDCs, neither LDC\n",
    "\n",
    "    # get the two LDCs' territories\n",
    "    ldc1 = ldcs_ornl.loc[ldcs_ornl['EIA company ID']==ldc1_id].reset_index(drop=True)\n",
    "    ldc2 = ldcs_ornl.loc[ldcs_ornl['EIA company ID']==ldc2_id].reset_index(drop=True)\n",
    "\n",
    "    # find the two LDCs' territories that are within the selected urban area\n",
    "    ldc1_urb = gpd.overlay(ldc1, sel_urban_area, how='intersection')\n",
    "    ldc2_urb = gpd.overlay(ldc2, sel_urban_area, how='intersection')\n",
    "\n",
    "    # find the two LDCs' territories within the selected urban area that are also within the selected tract\n",
    "    ldc1_urb_tract = gpd.overlay(ldc1_urb, tract_sel, how='intersection')\n",
    "    ldc2_urb_tract = gpd.overlay(ldc2_urb, tract_sel, how='intersection')\n",
    "\n",
    "    try:\n",
    "        both_ldcs = gpd.overlay(\n",
    "            ldc1_urb_tract.drop(['LDC name', 'EIA company ID'], axis=1), \n",
    "            ldc2_urb_tract[['geometry']], \n",
    "            how='intersection')\n",
    "\n",
    "        if len(both_ldcs) == 0:\n",
    "            # There were 2 LDCs in the tract, but no overlap in their service territories\n",
    "            # No overlap requiring split of population, so skip both_ldcs steps\n",
    "            pass\n",
    "\n",
    "        elif len(both_ldcs) > 1:\n",
    "            # There were 2 LDCs in the tract, with at least partially overlapping territories\n",
    "            # Sort them out\n",
    "            both_ldcs = both_ldcs.reset_index(drop=True)\n",
    "\n",
    "            # calculate for portion served by both LDCs\n",
    "            both_ldcs['km2 served'] = both_ldcs.area * km2_per_m2\n",
    "            both_ldcs['pop served 2 LDCs'] = both_ldcs['pop per km2'] * both_ldcs['km2 served']\n",
    "            split_pop = both_ldcs.at[0, 'pop served 2 LDCs']/2\n",
    "            ldc1_split_pop = both_ldcs.copy()\n",
    "\n",
    "            for ldc_id in [ldc1_id, ldc2_id]:\n",
    "                ldc_split = both_ldcs.copy()\n",
    "                ldc_split['EIA company ID'] = ldc_id\n",
    "                ldc_split['LDC name'] = ldcs_ornl.loc[ldcs_ornl['EIA company ID']==ldc_id].reset_index(drop=True).at[0, 'LDC name']\n",
    "                ldc_split['pop served'] = split_pop\n",
    "                ldc_split = ldc_split.drop('pop served 2 LDCs', axis=1)\n",
    "                tract_results = tract_results.append(ldc_split, sort=False)\n",
    "\n",
    "        only_ldc1 = gpd.overlay(ldc1_urb_tract, ldc2_urb_tract, how='difference')\n",
    "        only_ldc1['km2 served'] = only_ldc1.area * km2_per_m2\n",
    "        only_ldc1['pop served'] = only_ldc1['pop per km2'] * only_ldc1['km2 served']\n",
    "        tract_results = tract_results.append(only_ldc1, sort=False)\n",
    "\n",
    "        only_ldc2 = gpd.overlay(ldc2_urb_tract, ldc1_urb_tract, how='difference')\n",
    "        only_ldc2['km2 served'] = only_ldc2.area * km2_per_m2\n",
    "        only_ldc2['pop served'] = only_ldc2['pop per km2'] * only_ldc2['km2 served']\n",
    "        tract_results = tract_results.append(only_ldc2, sort=False)\n",
    "\n",
    "        # to get portion of tract that is in neither LDC territory:\n",
    "        # unitary union or dissolve of two (or more) LDC territories\n",
    "        # overlay difference, with tract first and territories second\n",
    "        both_ldcs_ornl = ldcs_ornl.loc[ldcs_ornl['EIA company ID'].isin([ldc1_id, ldc2_id])]\n",
    "        no_ldc = gpd.overlay(tract_sel, both_ldcs_ornl, how='difference').reset_index(drop=True)\n",
    "        no_ldc['km2 served'] = no_ldc.area * km2_per_m2\n",
    "        no_ldc['pop served'] = no_ldc['pop per km2'] * no_ldc['km2 served']\n",
    "        no_ldc['urban name'] = sel_urb_name\n",
    "        no_ldc['EIA company ID'] = 'no LDC and/or not in urban'\n",
    "        no_ldc['LDC name'] = 'no LDC and/or not in urban'\n",
    "        tract_results = tract_results.append(no_ldc, sort=False)\n",
    "\n",
    "    except:\n",
    "        sel_geoid = tract_sel.at[0, 'tract GEOID']\n",
    "        print(f\"both_ldcs intersection failed for tract GEOID: {sel_geoid}, for EIA company IDs: {ldcs_ids}\")\n",
    "\n",
    "    return tract_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_tract_pop_between_major_ldcs_equally(ldcs_sel_urb_tract_majors):\n",
    "    num_major_ldcs = len(ldcs_sel_urb_tract_majors)\n",
    "    tract_pop = ldcs_sel_urb_tract_majors['tract pop'].max()\n",
    "    pop_per_ldc = tract_pop / num_major_ldcs\n",
    "    ldcs_sel_urb_tract_majors['pop served'] = pop_per_ldc\n",
    "    \n",
    "    tract_results = ldcs_sel_urb_tract_majors.drop(['fract cov'], axis=1)\n",
    "    \n",
    "    return tract_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_tract_pop_between_top_3_ldcs_equally(top_3):\n",
    "    num_major_ldcs = len(top_3)\n",
    "    tract_pop_served = top_3[['tract pop', 'fract cov']].product(axis=1, skipna=None).sum()\n",
    "    pop_per_ldc = tract_pop_served / num_major_ldcs\n",
    "    top_3['pop served'] = pop_per_ldc\n",
    "    \n",
    "    tract_results = top_3\n",
    "    \n",
    "    return tract_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over all cities in Gas Index\n",
    "all_urb_tract_results = pd.DataFrame() # initialize\n",
    "\n",
    "for sel_urb_name in sel_urban_areas:\n",
    "    sel_urban_tract_results_list = [] # initialize\n",
    "    sel_urban_area = urban.loc[urban['urban name']==sel_urb_name]\n",
    "\n",
    "    sel_states = sel_urb_name.split(', ')[-1].split('--')\n",
    "    # print(sel_states) # for db\n",
    "    tracts_sel_states = all_tracts.loc[all_tracts['state abbrev'].isin(sel_states)]\n",
    "    # print(len(tracts_sel_states)) # for db\n",
    "    sel_urban_area_tracts = gpd.overlay(sel_urban_area, tracts_sel_states, how='intersection')\n",
    "    \n",
    "    sel_urban_area_tract_geoids_list = sel_urban_area_tracts['tract GEOID'].unique().tolist()\n",
    "    \n",
    "    ldcs_sel = ldcs_ornl.loc[ldcs_ornl['EIA company ID'].str[-2:].isin(sel_states)]\n",
    "    ldcs_sel_urb = gpd.overlay(ldcs_sel, sel_urban_area, how='intersection')\n",
    "    \n",
    "    # select LDCs in sel_states\n",
    "    number_of_tracts = len(sel_urban_area_tract_geoids_list)\n",
    "    print(f\"{sel_urb_name}: processing {number_of_tracts} tracts\")\n",
    "\n",
    "    counter = 0 # initialize\n",
    "    for sel_geoid in sel_urban_area_tract_geoids_list:\n",
    "        try:\n",
    "            # select one tract\n",
    "            tract_sel = all_tracts.copy().loc[all_tracts['tract GEOID']==sel_geoid].reset_index(drop=True)\n",
    "\n",
    "            # find the LDCs serving the given tract\n",
    "            ldcs_sel_urb_tract = gpd.overlay(ldcs_sel_urb, tract_sel, how='intersection')\n",
    "\n",
    "            ldcs_sel_urb_tract['km2 served'] = ldcs_sel_urb_tract.area * km2_per_m2\n",
    "\n",
    "            # filter out minor pieces (< 1% of area); if that filters down to 2 or less LDCs, use those\n",
    "            ldcs_sel_urb_tract['fract cov'] = ldcs_sel_urb_tract['km2 served'] / ldcs_sel_urb_tract['tract km2']\n",
    "            ldcs_sel_urb_tract = ldcs_sel_urb_tract.copy().loc[ldcs_sel_urb_tract['fract cov'] > 0.01]\n",
    "\n",
    "            if len(ldcs_sel_urb_tract)==0:\n",
    "                # no service\n",
    "                pass\n",
    "\n",
    "            elif len(ldcs_sel_urb_tract)==1:\n",
    "                # ldc_id = ldcs_sel_urb_tract['EIA company ID'].tolist()[0]\n",
    "                # tract_results = allocate_tract_pop_to_one_ldc(tract_sel, ldcs_sel_urb, ldc_id) # sel_urban_area\n",
    "                # tract_results = allocate_tract_pop_to_one_ldc(tract_sel, ldcs_sel_urb_tract) # sel_urban_area\n",
    "                tract_results = allocate_tract_pop_to_one_ldc(tract_sel, ldcs_sel_urb_tract, ldcs_sel_urb)\n",
    "                sel_urban_tract_results_list.append(tract_results)\n",
    "\n",
    "            elif len(ldcs_sel_urb_tract)==2:\n",
    "                ldcs_ids = ldcs_sel_urb_tract['EIA company ID'].tolist()\n",
    "                tract_results = allocate_tract_pop_between_two_ldcs(tract_sel, sel_urban_area, ldcs_ids)\n",
    "                sel_urban_tract_results_list.append(tract_results)\n",
    "\n",
    "            elif len(ldcs_sel_urb_tract) > 2:\n",
    "                # ldcs_sel_urb_tract['km2 served'] = ldcs_sel_urb_tract.area * km2_per_m2\n",
    "                ldcs_sel_urb_tract = ldcs_sel_urb_tract.sort_values(by=['km2 served'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "                ldcs_sel_urb_tract_majors = ldcs_sel_urb_tract.copy().loc[ldcs_sel_urb_tract['fract cov']>=0.75]\n",
    "                if len(ldcs_sel_urb_tract_majors) > 2:\n",
    "                    # there are more than 2 LDCs that each cover at least 75% of the tract\n",
    "                    # split the population equally between all the major LDCs\n",
    "                    tract_results = allocate_tract_pop_between_major_ldcs_equally(ldcs_sel_urb_tract_majors)\n",
    "                    sel_urban_tract_results_list.append(tract_results)\n",
    "\n",
    "                else:\n",
    "                    # not more than 2 LDCs covering >= 75% of area\n",
    "                    # print(f\"case with > 2 LDCs serving tract, but not more than 2 covering >= 75% of area: tract GEOID: {sel_geoid}\") # for db\n",
    "\n",
    "                    # try filtering out small pieces (< 5%); if that filters down to 2 or less LDCs, use those\n",
    "                    ldcs_sel_urb_tract_excl_minor = ldcs_sel_urb_tract.copy().loc[ldcs_sel_urb_tract['fract cov'] > 0.05]\n",
    "                    if len(ldcs_sel_urb_tract_excl_minor)==1:\n",
    "                        print(\"---- after filtering out < 5%, only 1 LDC\")\n",
    "                        tract_results = allocate_tract_pop_to_one_ldc(tract_sel, ldcs_sel_urb_tract_excl_minor, ldcs_sel_urb)\n",
    "                        sel_urban_tract_results_list.append(tract_results)\n",
    "\n",
    "                    elif len(ldcs_sel_urb_tract_excl_minor) == 2:\n",
    "                        print(\"---- after filtering out < 5%, only 2 LDCs\")\n",
    "                        ldcs_ids = ldcs_sel_urb_tract_excl_minor['EIA company ID'].tolist()\n",
    "                        tract_results = allocate_tract_pop_between_two_ldcs(tract_sel, sel_urban_area, ldcs_ids)\n",
    "                        sel_urban_tract_results_list.append(tract_results)\n",
    "\n",
    "                    else:\n",
    "                        # check if top 3 cover about the same fraction; if so, split equally\n",
    "                        top_3 = ldcs_sel_urb_tract_excl_minor.loc[ldcs_sel_urb_tract_excl_minor.index.isin([0, 1, 2])]\n",
    "\n",
    "                        if (top_3['fract cov'].std() / top_3['fract cov'].mean()) < 0.2:\n",
    "                            # the top 3 LDCs cover about the same area; divide area between them equally\n",
    "                            tract_results = allocate_tract_pop_between_top_3_ldcs_equally(top_3)\n",
    "                            sel_urban_tract_results_list.append(tract_results)\n",
    "\n",
    "                        else:\n",
    "                            # variation among the top 3; choose the 2 largest                    \n",
    "                            ldcs_sel_urb_tract_excl_minor_largest = ldcs_sel_urb_tract_excl_minor.copy().loc[\n",
    "                                ldcs_sel_urb_tract_excl_minor.index.isin([0, 1])]\n",
    "\n",
    "                            # TEST: after filtering step above, make sure only 2 rows remaining\n",
    "                            if len(ldcs_sel_urb_tract_excl_minor_largest)!=2:\n",
    "                                print(f\"len(ldcs_sel_urb_tract) supposed to be 2, but it is: {len(ldcs_sel_urb_tract_excl_minor_largest)}\")\n",
    "                            # END OF TEST\n",
    "\n",
    "                            ldcs_ids = ldcs_sel_urb_tract_excl_minor_largest['EIA company ID'].tolist()\n",
    "                            tract_results = allocate_tract_pop_between_two_ldcs(tract_sel, sel_urban_area, ldcs_ids)\n",
    "                            sel_urban_tract_results_list.append(tract_results)\n",
    "\n",
    "            else:\n",
    "                print(\"ERROR!\" + f\" Unexpected value for len(ldcs_sel_urb_tract): {len(ldcs_sel_urb_tract)}\")\n",
    "\n",
    "            counter += 1\n",
    "            if counter % 100 == 0:\n",
    "                print(f\"-- Processed {counter} tracts; len(sel_urban_tract_results_list): {len(sel_urban_tract_results_list)}\")\n",
    "                \n",
    "        except: # with try just after for sel_geoid in ...\n",
    "            print(f\"---- Not able to process sel_geoid {sel_geoid}; could be TopologyException\")\n",
    "            print(\"For tract 28121020302 in Jackson, MS, got error: 'TopologyException: no outgoing dirEdge found at 928240.987367964 -1358326.433380282'\")\n",
    "\n",
    "    # end of one urban area; compile into df & append to main df\n",
    "    sel_urban_tract_results = pd.concat(sel_urban_tract_results_list, sort=False)\n",
    "    all_urb_tract_results = all_urb_tract_results.append(sel_urban_tract_results, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urb_tract_results = all_urb_tract_results.reset_index()\n",
    "print(len(all_urb_tract_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export results\n",
    "save_timestamp = time.strftime('%Y-%m-%d_%H%M', time.localtime())\n",
    "all_urb_tract_results.to_excel(lca_path + f'GIM LDCs alloc all_urb_tract_results {save_timestamp}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there were 34 tracts with fract served > 1\n",
    "# renormalize these by adjusting pop served\n",
    "df = all_urb_tract_results.groupby(\n",
    "    ['urban name', 'tract GEOID', 'tract pop'])[['pop served']].sum().reset_index()\n",
    "df['fract served'] = df['pop served'] / df['tract pop']\n",
    "overshoot = df.loc[df['fract served']>1.00001]\n",
    "overshoot = overshoot.rename(columns={'fract served': 'overshoot fract served'})\n",
    "\n",
    "# merge overshoot\n",
    "df2 = pd.merge(\n",
    "    all_urb_tract_results, overshoot[['tract GEOID', 'overshoot fract served']],\n",
    "    on='tract GEOID', how='left')\n",
    "df2['overshoot fract served'] = df2['overshoot fract served'].fillna(1)\n",
    "df2['pop served'] = df2['pop served'] / df2['overshoot fract served']\n",
    "df2['check ratios'] = df2['pop served'] / df2['tract pop']\n",
    "\n",
    "all_urb_tract_results = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_results_ldcs = all_urb_tract_results.loc[all_urb_tract_results['EIA company ID']!='no LDC and/or not in urban']\n",
    "urb_ldcs_pop_served = tract_results_ldcs.groupby(['urban name', 'EIA company ID'])[['pop served']].sum().reset_index()\n",
    "print(len(urb_ldcs_pop_served))\n",
    "\n",
    "# remove all rows with pop served < 1\n",
    "urb_ldcs_pop_served = urb_ldcs_pop_served.loc[urb_ldcs_pop_served['pop served']>1]\n",
    "print(len(urb_ldcs_pop_served))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urb_ldcs_pop_served = urb_ldcs_pop_served.sort_values(by=['urban name', 'pop served'], ascending=[True, False]).reset_index(drop=True)\n",
    "urb_ldcs_pop_served = urb_ldcs_pop_served.rename(columns={'pop served': '1LDC pop served in 1urb'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urb_ldcs_pop_served"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## put back in individual cities with special handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in_individual_cities(\n",
    "    urban_name, eia_id, urb_ldcs_pop_served, urban, all_tracts): # ldc_name\n",
    "\n",
    "    # ---------------\n",
    "    # calculate urban population\n",
    "    # get urban area shape\n",
    "    urb_shp = urban.loc[urban['urban name']==urban_name]\n",
    "\n",
    "    # select census tracts for relevant states\n",
    "    states_covered_abbrev = urban_name.split(', ')[-1].split('--')\n",
    "    tracts_sel = all_tracts.loc[all_tracts['state abbrev'].isin(states_covered_abbrev)]\n",
    "\n",
    "    test_for_crs_mismatch(urb_shp, tracts_sel)\n",
    "\n",
    "    # intersection with census tracts (with population) for states covered: whole urban area\n",
    "    urb_tract = gpd.overlay(urb_shp, tracts_sel, how='intersection')\n",
    "    urb_pop = urb_tract['tract pop'].sum()\n",
    "\n",
    "    # put values into urb_ldcs_pop_served\n",
    "    df = urb_ldcs_pop_served.copy()\n",
    "    new_index = urb_ldcs_pop_served.index.max()+1\n",
    "    df.at[new_index, 'urban name'] = urban_name\n",
    "    df.at[new_index, 'EIA company ID'] = eia_id\n",
    "    df.at[new_index, '1LDC pop served in 1urb'] = urb_pop\n",
    "\n",
    "    urb_ldcs_pop_served_mod = df\n",
    "    return urb_ldcs_pop_served_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urb_ldcs_pop_served_mod = urb_ldcs_pop_served.copy()\n",
    "\n",
    "urb_ldcs_pop_served_mod = fill_in_individual_cities(\n",
    "    'Lawrence, KS', '17681028KS', \n",
    "    urb_ldcs_pop_served_mod, urban, all_tracts)\n",
    "\n",
    "urb_ldcs_pop_served_mod = fill_in_individual_cities(\n",
    "    'Cedar Rapids, IA', '17650918IA',\n",
    "    urb_ldcs_pop_served_mod, urban, all_tracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import EIA data on gas deliveries by each LDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_operations_file_and_calculate_sectoral_groups(operations_year_file, contiguous_us_only):\n",
    "    \"\"\"\n",
    "    Note: for at least one utility (Midwest Energy, in Kansas), there is a mismatch\n",
    "    between EIA data in operations file and in deliveries file.\n",
    "    \n",
    "    In deliveries file, this utility's data is split between two different IDs,\n",
    "    whereas in operations file, it's under one ID.\n",
    "    \n",
    "    The deliveries file is not used in GIM.\n",
    "    \"\"\"\n",
    "    # use EIA-176 \"Type of Operation\" data set that has customer numbers\n",
    "    df = pd.read_excel(eia_176_path + operations_year_file, sheet_name='Sheet 1', header=1)\n",
    "    df = df.rename(columns={\n",
    "        'Company': 'EIA company ID',\n",
    "        'Company Name': 'EIA company name',\n",
    "        'Residential Total Volume (Mcf)': 'LDC total res Mcf', \n",
    "        'Commercial Total Volume (Mcf)': 'LDC total comm Mcf',\n",
    "        'Electric Total Volume (Mcf)': 'LDC total elec Mcf',\n",
    "        'Industrial Total Volume (Mcf)': 'LDC total ind Mcf',\n",
    "        'Vehicle Fuel Total Volume (Mcf)': 'LDC total veh Mcf',\n",
    "    })\n",
    "    \n",
    "    df['LDC total all sectors Mcf'] = df[[\n",
    "        'LDC total res Mcf',\n",
    "        'LDC total comm Mcf',\n",
    "        'LDC total elec Mcf',\n",
    "        'LDC total ind Mcf',\n",
    "        'LDC total veh Mcf',\n",
    "    ]].sum(axis=1)\n",
    "    \n",
    "    print(f\"all US deliveries (Bcf): {round(df['LDC total all sectors Mcf'].sum() / 1e6, 1)}\")\n",
    "    \n",
    "    df = consolidate_national_grid_in_new_york(df)\n",
    "    df = consolidate_northeast_ohio_gas(df)\n",
    "    \n",
    "    # filter for only contiguous US (depending on parameter setting)\n",
    "    if contiguous_us_only == True:\n",
    "        df = df.loc[~df['State'].isin(['AK', 'HI', 'PR'])]\n",
    "        \n",
    "    print(f\"contiguous US deliveries (Bcf): {round(df['LDC total all sectors Mcf'].sum() / 1e6, 1)}\")\n",
    "        \n",
    "    # remove all adjustment companies \n",
    "    # (none of them have any volumes or customer numbers anyway, at least for 2018)\n",
    "    df = df.loc[df['EIA company name']!='ADJUSTMENT COMPANY']\n",
    "    \n",
    "    print(f\"contiguous US deliveries excl. adjustment companies (Bcf): {round(df['LDC total all sectors Mcf'].sum() / 1e6, 1)}\")\n",
    "   \n",
    "    df = df[[\n",
    "        'EIA company ID', 'EIA company name', \n",
    "        'LDC total res Mcf', 'LDC total comm Mcf', \n",
    "        'LDC total elec Mcf', 'LDC total ind Mcf',\n",
    "        'LDC total veh Mcf',\n",
    "        'LDC total all sectors Mcf']]\n",
    "    \n",
    "    operations_year = df\n",
    "    \n",
    "    return operations_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations_year = read_operations_file_and_calculate_sectoral_groups(\n",
    "    operations_year_file, contiguous_us_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge city & LDC data: \n",
    "* bring in ldc_population_served, with total population served by each LDC\n",
    "* calculate the share of each LDC's population served that is within each urban area\n",
    "* then merge in EIA data on gas deliveries\n",
    "* assume gas deliveries are proportional to population, to calculate gas deliveries by each LDC to each urban area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_ldc_urban(urb_ldcs_pop_served_mod, ldc_population_served, operations_year):\n",
    "    df = pd.merge(urb_ldcs_pop_served_mod, ldc_population_served, on='EIA company ID', how='left')\n",
    "    df['LDC fract to 1urb'] = df['1LDC pop served in 1urb'] / df['LDC pop served']\n",
    "\n",
    "    df = pd.merge(df, operations_year, on='EIA company ID', how='left')\n",
    "    df['1LDC 1urb res Mcf'] = df['LDC total res Mcf'] * df['LDC fract to 1urb']\n",
    "    df['1LDC 1urb comm Mcf'] = df['LDC total comm Mcf'] * df['LDC fract to 1urb']\n",
    "    df['1LDC 1urb res-comm Mcf'] = df[['1LDC 1urb res Mcf', '1LDC 1urb comm Mcf']].sum(axis=1)\n",
    "    df = df.drop(['1LDC 1urb res Mcf', '1LDC 1urb comm Mcf'], axis=1)\n",
    "    \n",
    "    df['1LDC 1urb elec Mcf'] = df['LDC total elec Mcf'] * df['LDC fract to 1urb']\n",
    "    df['1LDC 1urb ind Mcf'] = df['LDC total ind Mcf'] * df['LDC fract to 1urb']\n",
    "    # df['1LDC 1urb veh Mcf'] = df['LDC total veh Mcf'] * df['LDC fract to 1urb']\n",
    "    df['1LDC 1urb all sect Mcf'] = df['LDC total all sectors Mcf'] * df['LDC fract to 1urb']\n",
    "\n",
    "    df = df.drop([\n",
    "        'LDC name',\n",
    "        '1LDC pop served in 1urb', 'LDC pop served',\n",
    "        'LDC total res Mcf', 'LDC total comm Mcf', 'LDC total elec Mcf',\n",
    "        'LDC total ind Mcf', 'LDC total veh Mcf', \n",
    "        'LDC total all sectors Mcf',\n",
    "    ], axis=1)\n",
    "\n",
    "    all_ldc_urban = df\n",
    "    return all_ldc_urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ldc_urban = create_all_ldc_urban(urb_ldcs_pop_served_mod, ldc_population_served, operations_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate quantities of methane leakage from each LDC allocated to each urban area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ldc_leak_rcei():\n",
    "    # read results from previous notebook (GIM LDC leakage)\n",
    "    ldc_leak_rcei_file = f'GIM LDC res-comm-elec-ind leak for {data_year} {ldc_leak_rcei_timestamp}.csv'\n",
    "    ldc_leak = pd.read_csv(lca_path + ldc_leak_rcei_file)\n",
    "\n",
    "    ldc_leak_keep_cols = [\n",
    "        'EIA company ID',\n",
    "        # 'total deliv NG Mcf',\n",
    "        'dist pipe res-comm leak CH4 Gg', 'res-comm meter leak CH4 Gg', 'behind-the-meter res-comm CH4 Gg',\n",
    "        # 'LDC res-comm leak total CH4 Gg',\n",
    "        'dist pipe elec leak CH4 Gg', 'elec meter leak CH4 Gg',\n",
    "        # 'LDC elec leak total CH4 Gg', \n",
    "        'dist pipe ind leak CH4 Gg', 'indust meter leak CH4 Gg',\n",
    "        # 'LDC ind leak total CH4 Gg'\n",
    "    ]\n",
    "    ldc_leak = ldc_leak[ldc_leak_keep_cols]\n",
    "    ldc_leak = ldc_leak.set_index('EIA company ID')\n",
    "    \n",
    "    return ldc_leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_leakage_rates_by_urban_area(all_ldc_urban, ldc_leak, operations_year):\n",
    "    # merge in leakage data from previous notebook\n",
    "    df = pd.merge(all_ldc_urban, ldc_leak, on='EIA company ID', how='left')\n",
    "    leak_cols = [\n",
    "        'dist pipe res-comm leak CH4 Gg', 'res-comm meter leak CH4 Gg', 'behind-the-meter res-comm CH4 Gg',\n",
    "        'dist pipe elec leak CH4 Gg', 'elec meter leak CH4 Gg',\n",
    "        'dist pipe ind leak CH4 Gg', 'indust meter leak CH4 Gg'\n",
    "    ]\n",
    "    leak_cols_new = [] # initialize\n",
    "    for col in leak_cols:\n",
    "        new_col = col + ' 1urb'\n",
    "        df[new_col] = df[col] * df['LDC fract to 1urb']   \n",
    "        df = df.drop(col, axis=1)\n",
    "        leak_cols_new += [new_col]\n",
    "\n",
    "    ungrouped = df.copy()\n",
    "        \n",
    "    all_ldc_urban_vol_cols = [\n",
    "        '1LDC 1urb res-comm Mcf', \n",
    "        '1LDC 1urb elec Mcf', \n",
    "        '1LDC 1urb ind Mcf', '1LDC 1urb all sect Mcf'\n",
    "    ]\n",
    "        \n",
    "    df = df.groupby('urban name')[leak_cols_new + all_ldc_urban_vol_cols].sum()\n",
    "    df = df.reset_index()\n",
    "    for col in df.columns:\n",
    "        if '1LDC 1urb' in col:\n",
    "            new_col = col.replace('1LDC 1urb', '1urb')\n",
    "            df = df.rename(columns={col: new_col})\n",
    "\n",
    "    # leak rates:\n",
    "    # calculate leakage rate for each component, based on the gas deliveries for the corresponding sector\n",
    "    for col in leak_cols_new:\n",
    "        if 'res-comm' in col:\n",
    "            sector = 'res-comm'\n",
    "        elif 'elec' in col:\n",
    "            sector = 'elec'\n",
    "        elif 'ind' in col:\n",
    "            sector = 'ind'\n",
    "#         elif 'veh' in col:\n",
    "#             sector = 'veh'\n",
    "        else:\n",
    "            print(\"ERROR!\" + f\" Unexpected value for col: {col}\")\n",
    "\n",
    "        rate_col = col.replace('CH4 Gg', 'CH4 g/Mcf')\n",
    "            \n",
    "        df[rate_col] = (df[col] * g_per_gg) / df[f'1urb {sector} Mcf']\n",
    "        \n",
    "    result = df\n",
    "    return(result, ungrouped)\n",
    "# end of calculate_leakage_rates_by_urban_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldc_leak = read_ldc_leak_rcei()\n",
    "(result, ungrouped) = calculate_leakage_rates_by_urban_area(all_ldc_urban, ldc_leak, operations_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "save_timestamp = time.strftime('%Y-%m-%d_%H%M', time.localtime())\n",
    "ungrouped.to_excel(\n",
    "    lca_path + f'GIM results - LDCs allocation to cities - ungrouped {save_timestamp}.xlsx', \n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungrouped.loc[ungrouped['urban name']=='Boise City, ID'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bcf\n",
    "ungrouped.loc[ungrouped['urban name']=='Indianapolis, IN']['1LDC 1urb all sect Mcf'].sum()/1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile results for cities in index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production area leakage results, by consuming state:\n",
    "prod_leak_file = f'GIM production area leakage rate by consuming state for 2018 {prod_leak_timestamp}.csv'\n",
    "prod_leak = pd.read_csv(lca_path + prod_leak_file)\n",
    "if prod_leak.columns[0]=='Unnamed: 0':\n",
    "    prod_leak = prod_leak.rename(columns={'Unnamed: 0': 'state'})\n",
    "prod_leak['state abbrev'] = prod_leak['state'].replace(states_full_to_abbrev_dict)\n",
    "prod_leak = prod_leak.loc[~prod_leak['state'].isin(['Canada', 'Mexico'])]\n",
    "\n",
    "# simple approach: assign a single state to each urban area\n",
    "# (more complex approach would be to assign a weighted average across states, when more than one state)\n",
    "# (however, there generally isn't a big difference in the production-area leakage value for neighboring consuming states,\n",
    "# at least for any urban areas in the index that cross state boundaries)\n",
    "result['state abbrev'] = result['urban name'].str.split(', ').str[-1].str.split('--').str[0]\n",
    "\n",
    "result_states_initial = result['state abbrev'].unique().tolist()\n",
    "result = pd.merge(\n",
    "    result,\n",
    "    prod_leak[['state abbrev', 'prod leak g CH4/Mcf dry gas']],\n",
    "    on='state abbrev', how='outer'\n",
    ")\n",
    "for name in result_states_initial:\n",
    "    if name not in result['state abbrev'].unique().tolist():\n",
    "        print(\"ERROR!\" + f\" Change in urban name: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transmission area leakage results\n",
    "trans_leak_file = f'GIM trans leak by city for 2018 {trans_leak_timestamp}.csv'\n",
    "trans_leak = pd.read_csv(lca_path + trans_leak_file)\n",
    "\n",
    "result_urban_names_initial = result['urban name'].unique().tolist()\n",
    "result = pd.merge(\n",
    "    result, \n",
    "    trans_leak[['urban name', 'trans leak g CH4/Mcf']].dropna(subset=['urban name']), \n",
    "    on='urban name', how='outer')\n",
    "for name in result_urban_names_initial:\n",
    "    if name not in result['urban name'].unique().tolist():\n",
    "        print(\"ERROR!\" + f\" Change in urban name: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show rows with nan; if only DE & NJ, that's expected\n",
    "result.loc[result['urban name'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.loc[result['urban name'].isna()==False]\n",
    "result = result.drop('state abbrev', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City leakage measurements\n",
    "Calculate additional emissions based on measurements of leakage within cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(inputs_path + parameters_file, sheet_name='urban area leakage')\n",
    "citywide_meas_leak_fracts = df.set_index('urban area')['leakage rate (% of CH4 delivered that leaks)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the corresponding methane leakage rate in g CH4/Mcf gas delivered\n",
    "citywide_leak_g_mcf = citywide_meas_leak_fracts * conversion_consumer_ng_mcf_to_ch4_gg * g_per_gg\n",
    "citywide_leak_g_mcf.name = 'citywide measured g CH4/Mcf'\n",
    "\n",
    "# merge with results\n",
    "result = pd.merge(\n",
    "    result, citywide_leak_g_mcf, \n",
    "    left_on='urban name', right_index=True, \n",
    "    how='outer',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the corresponding quantity of methane leakage (Gg/y)\n",
    "# based on GIM estimate of NG deliveries to each urban area\n",
    "result['meas corr leak CH4 Gg/y'] = result[\n",
    "    ['citywide measured g CH4/Mcf', '1urb all sect Mcf']].product(axis=1, skipna=False) * gg_per_g\n",
    "\n",
    "# calculate additional leakage implied by measured citywide leakage\n",
    "leak_gg_components = [\n",
    "    'dist pipe res-comm leak CH4 Gg 1urb',\n",
    "    'res-comm meter leak CH4 Gg 1urb',\n",
    "    'behind-the-meter res-comm CH4 Gg 1urb',\n",
    "    'dist pipe elec leak CH4 Gg 1urb', 'elec meter leak CH4 Gg 1urb',\n",
    "    'dist pipe ind leak CH4 Gg 1urb', 'indust meter leak CH4 Gg 1urb',\n",
    "]\n",
    "result['GIM city leak Gg/y'] = result[leak_gg_components].sum(axis=1)\n",
    "result['add leak CH4 Gg/y'] = result['meas corr leak CH4 Gg/y'] - result['GIM city leak Gg/y']\n",
    "\n",
    "for row in result.index:\n",
    "    add_leak = result.at[row, 'add leak CH4 Gg/y']\n",
    "    if add_leak < 0:\n",
    "        # replace with zero\n",
    "        result.at[row, 'add leak CH4 Gg/y'] = 0\n",
    "        \n",
    "# partition additional leakage (Gg/y) across sectors & calculate leakage rate\n",
    "result['add leak res-comm CH4 g/Mcf 1urb rate'] = (result['add leak CH4 Gg/y'] * g_per_gg) / result['1urb all sect Mcf']\n",
    "result['add leak res-comm CH4 g/Mcf 1urb rate'] = result['add leak res-comm CH4 g/Mcf 1urb rate'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare results & export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rescomm = result.copy()[[\n",
    "    'urban name', \n",
    "    'prod leak g CH4/Mcf dry gas', \n",
    "    'trans leak g CH4/Mcf',\n",
    "    'dist pipe res-comm leak CH4 g/Mcf 1urb',\n",
    "    'res-comm meter leak CH4 g/Mcf 1urb',\n",
    "    'behind-the-meter res-comm CH4 g/Mcf 1urb',\n",
    "    'add leak res-comm CH4 g/Mcf 1urb rate'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rescomm['total rc leak g CH4/Mcf'] = result_rescomm[[\n",
    "    'prod leak g CH4/Mcf dry gas', \n",
    "    'trans leak g CH4/Mcf',\n",
    "    'dist pipe res-comm leak CH4 g/Mcf 1urb',\n",
    "    'res-comm meter leak CH4 g/Mcf 1urb',\n",
    "    'behind-the-meter res-comm CH4 g/Mcf 1urb',\n",
    "    'add leak res-comm CH4 g/Mcf 1urb rate'\n",
    "]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge in city short names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_names = gim_cities.copy()\n",
    "city_names['metro st'] = city_names['metro area'] + ', ' + city_names['metro area state']\n",
    "city_names = city_names.rename(columns={'Census urban area name': 'urban name'})\n",
    "result_rescomm = pd.merge(city_names[['metro st', 'urban name']], result_rescomm, on='urban name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rescomm = result_rescomm.sort_values(by='total rc leak g CH4/Mcf', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "save_timestamp = time.strftime('%Y-%m-%d_%H%M', time.localtime())\n",
    "result_rescomm.to_excel(\n",
    "    lca_path + f'GIM leakage res-comm by urban area compiled {save_timestamp}.xlsx',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## end of module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
