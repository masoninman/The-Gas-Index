{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# for haversine function for transmission distance calculations\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters from previous steps\n",
    "\n",
    "# for input files from gas flows sub-model\n",
    "num_iter = 5000\n",
    "# prod_leak_timestamp = '2020-10-11_0954'\n",
    "# prod_leak_timestamp = '2020-11-10_1856'\n",
    "prod_leak_timestamp = '2020-11-12_0701'\n",
    "\n",
    "# template for state files used for transmission distance calculations\n",
    "state_df_file_template = f'US gas model - consuming_state results supp_fract_prod {num_iter} iterations ({prod_leak_timestamp}).csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files from external sources\n",
    "eia_release_date = '2020-10-30'\n",
    "consump_file = f'EIA Natural Gas Consumption by End Use NG_CONS_SUM_DCU_NUS_A released {eia_release_date}.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other input files compiled by GEM\n",
    "# cities_file = 'US utilities by city (PHMSA & EIA) 2020-10-31.xlsx'\n",
    "cities_file = 'GIM cities in index 2020-10-31.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "lca_path = '/Users/masoninman/Dropbox/GEM/LCA of natural gas use/'\n",
    "model_path = lca_path + 'US cities LCA of gas model/'\n",
    "inputs_path = lca_path + 'US cities LCA of gas model/US gas model inputs/'\n",
    "eia_path = lca_path + 'EIA data for LCA of gas/'\n",
    "gas_consump_data_path = eia_path + 'EIA gas consumption data 2019 (released 2020-09-30)/'\n",
    "state_coords_file = 'US Census - center of population by state (2010 census) and FIPS Code.xlsx'\n",
    "state_abbrev_file = 'US states and abbreviations.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversions\n",
    "gg_per_kg = 1e-6\n",
    "g_per_ton = 1e6\n",
    "\n",
    "df = pd.read_excel(inputs_path + 'GIM parameters file.xlsx', sheet_name='main parameters')\n",
    "parameters_main = df.set_index('parameter name')['parameter value']\n",
    "\n",
    "data_year = int(parameters_main.at['data_year'])\n",
    "contiguous_us_only = parameters_main.at['contiguous_us_only']\n",
    "trans_leak_fract = parameters_main.at['trans_leak_fract']\n",
    "trans_distance_avg_km = parameters_main.at['trans_distance_avg_km']\n",
    "ch4_kg_per_mcf = parameters_main.at['ch4_kg_per_mcf']\n",
    "ch4_fract_in_ng_consumer_grade = parameters_main.at['ch4_fract_in_ng_consumer_grade']\n",
    "\n",
    "conversion_consumer_ng_mcf_to_ch4_gg = ch4_fract_in_ng_consumer_grade * ch4_kg_per_mcf * gg_per_kg\n",
    "trans_leak_per_km = trans_leak_fract / trans_distance_avg_km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transmission leakage\n",
    "* calculate distance traveled for gas to each state or city\n",
    "* apply leakage factor set at start of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total transmission leakage, and rate of leakage (g/Mcf)\n",
    "df = pd.read_excel(inputs_path + consump_file, sheet_name='Data 1', header=2)\n",
    "df['year'] = df['Date'].dt.year\n",
    "df = df.drop('Date', axis=1)\n",
    "df = df.set_index('year')\n",
    "\n",
    "mcf_per_mmcf = 1000\n",
    "tot_mcf_consump_year = df.at[data_year, 'U.S. Natural Gas Total Consumption (MMcf)'] * mcf_per_mmcf\n",
    "\n",
    "trans_leak_mcf_ch4_gg = tot_mcf_consump_year * trans_leak_fract * conversion_consumer_ng_mcf_to_ch4_gg\n",
    "print(f\"transmission leakage: {round(trans_leak_mcf_ch4_gg, 1)} Gg\")\n",
    "trans_leak_g_ch4_per_mcf = trans_leak_mcf_ch4_gg * 1e9 / tot_mcf_consump_year\n",
    "print(f\"transmission leakage rate: {round(trans_leak_g_ch4_per_mcf, 1)} g/Mcf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative method, based on transmission leakage %\n",
    "# (gives same answer)\n",
    "trans_leak_fract * ch4_fract_in_ng_consumer_grade * ch4_kg_per_mcf * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Alvarez 2018 (analysis for 2015)\n",
    "alvarez_trans_leak_gg = 1800\n",
    "tot_mcf_2015 = df.at[2015, 'U.S. Natural Gas Total Consumption (MMcf)'] * mcf_per_mmcf\n",
    "alvarez_trans_leak_g_ch4_per_mcf = alvarez_trans_leak_gg * 1e9 / tot_mcf_2015\n",
    "alvarez_trans_leak_g_ch4_per_mcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions to calculate transmission leakage by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_state_coords_and_abbrev(state_coords_file, state_abbrev_file):\n",
    "    state_coords = pd.read_excel(\n",
    "        inputs_path + state_coords_file, \n",
    "        sheet_name='data'\n",
    "    )\n",
    "    state_coords = state_coords.rename(columns={\n",
    "        'LATITUDE': 'Latitude',\n",
    "        'LONGITUDE': 'Longitude',\n",
    "        'STNAME': 'State',\n",
    "        'STATEFP': 'State FIPS Code'\n",
    "    })\n",
    "    \n",
    "    state_coords = state_coords.loc[state_coords['State']!='Puerto Rico']\n",
    "    \n",
    "    state_coords = state_coords.set_index('State')\n",
    "\n",
    "    # add to state_coords:\n",
    "\n",
    "    # for Canada, use center of Alberta\n",
    "    state_coords.at['Canada', 'Latitude'] = 56.031769\n",
    "    state_coords.at['Canada', 'Longitude'] =  -114.781056\n",
    "\n",
    "    # for Fed GOM\n",
    "    state_coords.at['GOM (federal)', 'Latitude'] = 28.748915\n",
    "    state_coords.at['GOM (federal)', 'Longitude'] = -89.065917\n",
    "\n",
    "    # for Mexico\n",
    "    state_coords.at['Mexico', 'Latitude'] = 19.944744\n",
    "    state_coords.at['Mexico', 'Longitude'] = -97.26833\n",
    "    \n",
    "    # -------\n",
    "    \n",
    "    states_df = pd.read_excel(inputs_path + state_abbrev_file)\n",
    "\n",
    "    states_dict_abbrev_to_full = states_df.set_index('abbrev')['state'].to_dict()\n",
    "    \n",
    "    states_dict_full_to_abbrev = states_df.set_index('state')['abbrev'].to_dict()\n",
    "    \n",
    "    return(state_coords, states_dict_abbrev_to_full, states_dict_full_to_abbrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clean_paths(state_df):\n",
    "    \"\"\"\n",
    "    Create simpler (\"clean\") paths for imports, removing loops and other repeats of states.\n",
    "    \n",
    "    Uses three subfunctions:\n",
    "    cut_middle_loops\n",
    "    cut_producing_loops\n",
    "    cut_consuming_loops\n",
    "    \"\"\"\n",
    "    for row in state_df.index:\n",
    "        path_list = state_df.at[row, 'path'].split('-')\n",
    "        consum_state = path_list[0]\n",
    "        prod_state = path_list[-1]\n",
    "        middle_states = path_list[1:-1]\n",
    "\n",
    "        if len(path_list) == 1:\n",
    "            path_list_clean = path_list\n",
    "        elif len(path_list) > 1:\n",
    "            path_list_clean = cut_middle_loops(consum_state, prod_state, middle_states)\n",
    "            path_list_clean = cut_producing_loops(path_list_clean, prod_state)\n",
    "            path_list_clean = cut_consuming_loops(path_list_clean, consum_state)\n",
    "        else:\n",
    "            print(\"Error!\" + f\" Unexpected case for path_list: {path_list}\")\n",
    "\n",
    "        state_df.at[row, 'clean path'] = str(path_list_clean)\n",
    "        \n",
    "    return(state_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_middle_loops(consum_state, prod_state, middle_states):\n",
    "    counts = Counter(middle_states)\n",
    "\n",
    "    for state in middle_states:\n",
    "        if counts[state] > 1:\n",
    "            # there's a loop; cut it out\n",
    "            middle_match = []\n",
    "            for num in range(0, len(middle_states)):\n",
    "                if middle_states[num] == state:\n",
    "                    middle_match.append(num)\n",
    "\n",
    "            # remove states from first index + 1 to last index\n",
    "            del middle_states[middle_match[0]+1:middle_match[-1]+1]\n",
    "\n",
    "    path_list_clean = [consum_state] + middle_states + [prod_state]\n",
    "    \n",
    "    return path_list_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_producing_loops(path_list, prod_state):    \n",
    "    for num in range(0, len(path_list)-1):\n",
    "        count_back = len(path_list)-2-num\n",
    "        state_to_check = path_list[count_back]\n",
    "\n",
    "        if prod_state == state_to_check:\n",
    "            # drop that state from the list, based on the number\n",
    "            del path_list[count_back]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # add back prod_state\n",
    "    path_list.append(prod_state)\n",
    "\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_consuming_loops(path_list, consum_state):\n",
    "    # find all indices that match consuming state\n",
    "    match = []\n",
    "    for num in range(0, len(path_list)):\n",
    "        if path_list[num] == consum_state:\n",
    "            match.append(num)\n",
    "\n",
    "    # take the last index that matches; del list elements before that\n",
    "    path_list = path_list[match[-1]:]\n",
    "\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_path_list(path_list, state_coords):\n",
    "    # iterate through the path, \n",
    "    # calculating distances between each successive pair of states in the list\n",
    "    path_dist = 0 # initialize\n",
    "    \n",
    "    # TEST: check that state_coords was read correctly\n",
    "    if len(state_coords)==0:\n",
    "        print('Error!' + f\" DataFrame state_coords was not read correctly; len: {len(state_coords)}\")\n",
    "    elif len(state_coords)>0:\n",
    "        if len(state_coords)==54:\n",
    "            pass\n",
    "        else:\n",
    "            # print('Warning!' + f\"DataFrame state_coords was expected to have len 54, but actually had len {len(state_coords)}\")\n",
    "            pass\n",
    "    # END OF TEST\n",
    "    \n",
    "    if len(path_list) > 1:\n",
    "        for state_1_num in range(0, len(path_list)-1):\n",
    "            state_2_num = state_1_num + 1\n",
    "\n",
    "            # get names of state_1 and state_2\n",
    "            state_1 = path_list[state_1_num]\n",
    "            state_2 = path_list[state_2_num]\n",
    "\n",
    "            try:\n",
    "                # get centroids of each state\n",
    "                state_1_lat = state_coords.at[state_1, 'Latitude']\n",
    "                state_1_lon = state_coords.at[state_1, 'Longitude']\n",
    "                state_2_lat = state_coords.at[state_2, 'Latitude']\n",
    "                state_2_lon = state_coords.at[state_2, 'Longitude']\n",
    "\n",
    "                # calculate distance between them\n",
    "                pair_dist = haversine(\n",
    "                    state_1_lon, state_1_lat,\n",
    "                    state_2_lon, state_2_lat)\n",
    "                                \n",
    "                # add that distance to path_dist\n",
    "                path_dist += pair_dist\n",
    "                \n",
    "            except:\n",
    "                # print(f\"Didn't find {state_2}; assumed 0 distance\") # for db\n",
    "                pass\n",
    "\n",
    "    return path_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_coord_list(coord_list):\n",
    "    # iterate through the list, \n",
    "    # calculating distances between each successive pair of coordinates in the list\n",
    "    \n",
    "    if len(coord_list)==1:\n",
    "        print(\"Error!\" + \" All coord_lists should have more than 1 tuple.\")\n",
    "        print(f\"coord_list: {coord_list}\")\n",
    "    \n",
    "    elif len(coord_list) > 1:\n",
    "        path_dist = 0 # initialize\n",
    "        \n",
    "        for coord_1_num in range(0, len(coord_list)-1):\n",
    "            coord_2_num = coord_1_num + 1\n",
    "            \n",
    "            coord_1_lat = coord_list[coord_1_num][0]\n",
    "            coord_1_lon = coord_list[coord_1_num][1]\n",
    "\n",
    "            coord_2_lat = coord_list[coord_2_num][0]\n",
    "            coord_2_lon = coord_list[coord_2_num][1]\n",
    "            \n",
    "            # calculate distance between them\n",
    "            pair_dist = haversine(\n",
    "                coord_1_lon, coord_1_lat,\n",
    "                coord_2_lon, coord_2_lat)\n",
    "            \n",
    "            # add that distance to path_dist\n",
    "            path_dist = path_dist + pair_dist\n",
    "            \n",
    "    else:\n",
    "        print(\"Error!\" + f\" len(coord_list) had unexpected value: {len(coord_list)}\")\n",
    "        \n",
    "    return path_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance_gas_travels_to_each_state(\n",
    "    contig_48_states_dc, state_df_file_template, prod_leak_timestamp):\n",
    "    state_distances_list = [] # initialize\n",
    "\n",
    "    for consuming_state in contig_48_states_dc:\n",
    "        print(f\"processing consuming_state: {consuming_state}\") # for UI\n",
    "\n",
    "        # create name of file using template, and inserting a particular state\n",
    "        state_df_file = state_df_file_template.replace('consuming_state', consuming_state)\n",
    "        \n",
    "        try:\n",
    "            state_df = pd.read_csv(inputs_path + f'GIM gas flows results {prod_leak_timestamp}/' + state_df_file)\n",
    "        except:\n",
    "            print(\"Error!\" + \" File not found. It may be that the state files need to be moved to the GIM inputs folder.\")\n",
    "            print(f\"File name: {state_df_file}\")\n",
    "\n",
    "        state_df = create_clean_paths(state_df)\n",
    "\n",
    "        for row in state_df.index:\n",
    "            path_str = state_df.at[row, 'clean path']\n",
    "            path_list = path_str.strip('\\[').strip('\\]').replace(\"'\", \"\").split(', ')\n",
    "\n",
    "            path_dist = process_one_path_list(path_list, state_coords)\n",
    "\n",
    "            state_df.at[row, 'path dist'] = path_dist\n",
    "\n",
    "        # after iterating through all rows (for all the paths),\n",
    "        # calculate the weighted average distance for each consuming state\n",
    "        state_df_weighted = state_df['share scaled'] * state_df['path dist']\n",
    "        state_avg_dist = state_df_weighted.sum()/state_df['share scaled'].sum()\n",
    "\n",
    "        # add result to list (to become df) for all states\n",
    "        state_distances_list += [(consuming_state, state_avg_dist)]\n",
    "\n",
    "    state_distances = pd.DataFrame(state_distances_list, columns=['state', 'avg distance (km)'])\n",
    "    \n",
    "    return state_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of jurisidictions to calculate leakage for, attributable to their consumption\n",
    "# contiguous 48 states + DC\n",
    "contig_48_states_dc = [\n",
    "    'Alabama', 'Arizona', 'Arkansas', 'California', 'Colorado',\n",
    "       'Connecticut', 'Delaware', 'District of Columbia', 'Florida', 'Georgia',\n",
    "       'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky',\n",
    "       'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan',\n",
    "       'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
    "       'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
    "       'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
    "       'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
    "       'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
    "       'West Virginia', 'Wisconsin', 'Wyoming'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(state_coords, states_dict_abbrev_to_full, states_dict_full_to_abbrev) = read_state_coords_and_abbrev(\n",
    "    state_coords_file, state_abbrev_file)\n",
    "\n",
    "state_distances = calc_distance_gas_travels_to_each_state(\n",
    "    contig_48_states_dc, state_df_file_template, prod_leak_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate nationwide average leakage fraction per distance\n",
    "trans_leak_fract_per_km = trans_leak_fract / trans_distance_avg_km\n",
    "\n",
    "# convert from leakage fraction to g CH4/Mcf\n",
    "trans_leak_g_ch4_per_mcf = trans_leak_fract_per_km * conversion_consumer_ng_mcf_to_ch4_gg * 1e9\n",
    "\n",
    "trans_leak_state = state_distances.copy()\n",
    "trans_leak_state['trans leak g CH4/Mcf'] = trans_leak_state['avg distance (km)'] * trans_leak_g_ch4_per_mcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "save_timestamp = time.strftime('%Y-%m-%d_%H%M', time.localtime())\n",
    "trans_leak_state.to_csv(\n",
    "    lca_path + f'GIM average transmission distance for gas by consuming state for analysis year {data_year} {save_timestamp}.csv', \n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_states_df_create_list(state_abbrev_file):\n",
    "    states_df = pd.read_excel(inputs_path + state_abbrev_file)\n",
    "    \n",
    "    if contiguous_us_only == True:\n",
    "        states_df = states_df.loc[~states_df['state'].isin(['Alaska', 'Hawaii'])]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    states_list = states_df['state'].tolist()\n",
    "    \n",
    "    all_jurisdictions_list = states_list + ['Canada', 'Mexico', 'overseas']\n",
    "    \n",
    "    return(states_list, all_jurisdictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_eia_consump_data(states_list, states_dict_full_to_abbrev):\n",
    "    \"\"\"\n",
    "    Import EIA data on gas consumption by state. Units are MMcf (million cubic feet).\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame() # initialize\n",
    "\n",
    "    for state in states_list:\n",
    "        state_abbrev = states_dict_full_to_abbrev[state]\n",
    "        consump_juris_df = pd.read_excel(\n",
    "            gas_consump_data_path +\n",
    "            f'NG_CONS_SUM_DCU_S{state_abbrev}_A.xls', \n",
    "            sheet_name='Data 1', \n",
    "            header=2,\n",
    "        )\n",
    "\n",
    "        consump_juris_df['year'] = consump_juris_df['Date'].astype(str).str.split('-').str[0].astype(int)\n",
    "\n",
    "        consump_juris_df = consump_juris_df.set_index('year')\n",
    "        consump_juris_df = consump_juris_df.drop('Date', axis=1)\n",
    "\n",
    "        # keep only data_year\n",
    "        consump_juris_df = consump_juris_df.loc[consump_juris_df.index==data_year]\n",
    "\n",
    "        # pull out total consumption series\n",
    "        consump_juris_df_tot = consump_juris_df[[f'{state} Natural Gas Total Consumption (MMcf)']]\n",
    "        consump_juris_df_tot = consump_juris_df_tot.rename(columns={f'{state} Natural Gas Total Consumption (MMcf)': state})\n",
    "\n",
    "        df = pd.concat([df, consump_juris_df_tot], axis=1)        \n",
    "    df = df.T\n",
    "    df = df.rename(columns={data_year: 'consump MMcf'})\n",
    "    consump_juris_tot_mmcf = df\n",
    "\n",
    "    return consump_juris_tot_mmcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(states_list, all_jurisdictions_list) = read_states_df_create_list(state_abbrev_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consump_juris_tot_mmcf = read_eia_consump_data(states_list, states_dict_full_to_abbrev)\n",
    "\n",
    "df = pd.merge(state_distances, consump_juris_tot_mmcf, left_on='state', right_index=True, how='outer')\n",
    "df['trans leak NG MMcf'] = trans_leak_per_km * df[['avg distance (km)', 'consump MMcf']].product(axis=1)\n",
    "\n",
    "# calculate total transmission leakage, based on transport of gas from state to state\n",
    "df['trans leak CH4 Gg'] = df['trans leak NG MMcf'] * 1000 * conversion_consumer_ng_mcf_to_ch4_gg\n",
    "\n",
    "if contiguous_us_only==True:\n",
    "    print(f\"transmission leakage for contiguous US (Gg): {round(df['trans leak CH4 Gg'].sum(), 1)}\")\n",
    "elif contiguous_us_only == False:\n",
    "    print(f\"transmission leakage for all US (Gg): {round(df['trans leak CH4 Gg'].sum(), 1)}\")\n",
    "    \n",
    "trans_leak_state_level = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export:\n",
    "save_timestamp = time.strftime('%Y-%m-%d_%H%M', time.localtime())\n",
    "trans_leak.to_excel(\n",
    "    lca_path + \n",
    "    f'GIM results - transmission leakage by consuming state {save_timestamp}.xlsx', \n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate transmission leakage rate g/Mcf\n",
    "# assume all gas consumed by end-users is transported over the average distance calculated\n",
    "\n",
    "# note that calculation of trans_leak_gg above is based on total consumption, \n",
    "# which includes \"lease and plant fuel consumption\"\n",
    "\n",
    "# to be more conservative, could assume zero distance for lease and plant fuel consumption\n",
    "# from EIA definitions\n",
    "# https://www.eia.gov/dnav/ng/TblDefs/ng_cons_sum_tbldef2.asp\n",
    "# Lease use: Natural gas used in well, field, and lease operations, such as gas used in drilling operations, heaters, dehydrators, and field compressors\n",
    "# Plant fuel: Natural gas used as fuel in natural gas processing plants\n",
    "\n",
    "trans_leak_g_ch4_per_mcf = (df['trans leak CH4 Gg'].sum()*1e9)/(consump_juris_tot_mmcf['consump MMcf'].sum()*1000)\n",
    "\n",
    "print(f\"trans_leak_g_ch4_per_mcf: {round(trans_leak_g_ch4_per_mcf, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transmission: for each city, calculate distance & emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_city_distances_gas_transmission(\n",
    "    cities_file, states_dict_abbrev_to_full, \n",
    "    state_df_file_template, prod_leak_timestamp):\n",
    "    \n",
    "    # import data on cities\n",
    "    cities = pd.read_excel(inputs_path + cities_file, sheet_name='data')\n",
    "    cities = cities.drop(['notes'], axis=1)\n",
    "    \n",
    "    city_distances_list = [] # initialize\n",
    "\n",
    "    city_coords = cities[['metro area', 'metro area state', 'Census urban area name',\n",
    "                          'latitude', 'longitude']].drop_duplicates()\n",
    "    city_coords = city_coords.set_index(['metro area', 'metro area state'])\n",
    "\n",
    "    for city_st in city_coords.index:\n",
    "        print(f\"processing {city_st}\")\n",
    "        city_coords_tuple = (city_coords.loc[city_st, 'latitude'], city_coords.loc[city_st, 'longitude'])\n",
    "\n",
    "        metro_area = city_st[0]\n",
    "        consuming_state_abbrev = city_st[1]\n",
    "        urban_name = city_coords.at[city_st, 'Census urban area name']\n",
    "        consuming_state = states_dict_abbrev_to_full[consuming_state_abbrev]\n",
    "\n",
    "        # create name of file using template, and inserting a particular state\n",
    "        state_df_file = state_df_file_template.replace('consuming_state', consuming_state)\n",
    "        state_df = pd.read_csv(inputs_path + f'GIM gas flows results {prod_leak_timestamp}/' + state_df_file)\n",
    "        state_df = create_clean_paths(state_df)\n",
    "\n",
    "        # TEST: check that sum of shares is 1 (within rounding error)\n",
    "        shares_sum = state_df['share scaled'].sum()\n",
    "        if abs(1 - shares_sum) < 1e-6:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Error!\" + f\" Shares sum is not 1 (within rounding error); it's: {shares_sum}\")\n",
    "        # END OF TEST\n",
    "\n",
    "        city_df = state_df.copy()\n",
    "\n",
    "        for row in state_df.index:\n",
    "            path_str = state_df.at[row, 'clean path']\n",
    "            path_list = path_str.strip('\\[').strip('\\]').replace(\"'\", \"\").split(', ')\n",
    "\n",
    "            coord_list = [] # initialize\n",
    "\n",
    "            path_coords_tuple_prev = () # initialize\n",
    "            for path_element in path_list:\n",
    "                try:\n",
    "                    path_coords_tuple = (state_coords.at[path_element, 'Latitude'], state_coords.at[path_element, 'Longitude'])\n",
    "                except:\n",
    "                    # print(\"Error!\" + f\" {path_element} is not in state_coords df; use path_coords_tuple_prev: {path_coords_tuple_prev}\") # for db\n",
    "                    path_coords_tuple = path_coords_tuple_prev\n",
    "\n",
    "                path_coords_tuple_prev = path_coords_tuple\n",
    "\n",
    "                coord_list.append(path_coords_tuple)\n",
    "\n",
    "            if len(path_list)==1:\n",
    "                # if the list has len == 1, it is for consumption that comes from production in the same state\n",
    "                # put the city coordinates at the start of the list, to calculate distance from city to center of state\n",
    "                coord_list = [city_coords_tuple] + coord_list\n",
    "\n",
    "            elif len(path_list)>1:\n",
    "                # replace the first tuple of coordinates (the consuming state) with the city's coordinates\n",
    "                del coord_list[0]\n",
    "                city_coords_tuple_list = [city_coords_tuple]\n",
    "                coord_list = city_coords_tuple_list + coord_list\n",
    "\n",
    "            path_dist = process_one_coord_list(coord_list)\n",
    "\n",
    "            city_df.at[row, 'path dist'] = path_dist\n",
    "\n",
    "        # after iterating through all rows (for all the paths),\n",
    "        # calculate the weighted average distance for each consuming state\n",
    "        if abs(1 - city_df['share scaled'].sum()) < 1e-3:\n",
    "            # then all fractional shares of imports add up to 1\n",
    "            # calculate average distance by multiplying fractional shares (column name is consuming state)\n",
    "            # by the path distance for that particular share        \n",
    "            city_avg_dist = (city_df['share scaled'] * city_df['path dist']).sum()\n",
    "\n",
    "            # add result to list (to become df) for all states\n",
    "            city_distances_list += [[metro_area, consuming_state_abbrev, urban_name, city_avg_dist]]\n",
    "        else:\n",
    "            print(\"Error!\" + f\" For {city_st}, the fractional shares didn't sum to 1: {city_df['share scaled'].sum()}\")\n",
    "\n",
    "    # after iterating through all cities, assemble into df\n",
    "    city_distances = pd.DataFrame(city_distances_list, columns=[\n",
    "        'metro area', 'metro area state', 'urban name', 'avg distance (km)'])\n",
    "    \n",
    "    return city_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_distances = calc_city_distances_gas_transmission(\n",
    "    cities_file, states_dict_abbrev_to_full, \n",
    "    state_df_file_template, prod_leak_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_distances.sort_values(by='avg distance (km)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"mean distance gas traveled to each city: {round(city_distances['avg distance (km)'].mean(), 1)} km\")\n",
    "ratio = city_distances['avg distance (km)'].max()/city_distances['avg distance (km)'].min()\n",
    "\n",
    "print(f\"ratio of max/min transmission distance: {round(ratio, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transmission leakage by city\n",
    "(adjustment to production and transmission leakage rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_trans_leak_by_city(city_distances):  \n",
    "    trans_leak_per_km = trans_leak_fract / trans_distance_avg_km\n",
    "    \n",
    "    df = city_distances.copy()\n",
    "    df['trans leakage fract'] = trans_leak_per_km * df['avg distance (km)']\n",
    "    \n",
    "    # convert to mass methane per volume of natural gas delivered\n",
    "    # convert vol NG to vol CH4, then convert vol CH4 to mass, then convert mass to other units\n",
    "    df['trans leak g CH4/Mcf'] = df['trans leakage fract'] * ch4_fract_in_ng_consumer_grade * (ch4_kg_per_mcf/1000) * g_per_ton\n",
    "\n",
    "    df['full state'] = df['metro area state'].replace(states_dict_abbrev_to_full)\n",
    "\n",
    "    df = df[[\n",
    "        'metro area',\n",
    "        'metro area state',\n",
    "        'urban name',\n",
    "        'avg distance (km)',\n",
    "        'trans leak g CH4/Mcf',\n",
    "    ]]\n",
    "\n",
    "    trans_leak_by_city = df\n",
    "    \n",
    "    return trans_leak_by_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_leak_by_city = calc_trans_leak_by_city(city_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show\n",
    "trans_leak_by_city.sort_values(by='trans leak g CH4/Mcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "save_timestamp = time.strftime('%Y-%m-%d_%H%M', time.localtime())\n",
    "trans_leak_by_city.to_csv(\n",
    "    f'GIM trans leak by city for {data_year} {save_timestamp}.csv', \n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
